{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/seismosmsr/machine_learning/blob/main/LandCover_UNET.ipynb",
      "authorship_tag": "ABX9TyMes7KrgBLA2HqndzKDFxr8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/LandCover_UNET_08_22_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_OzYtqdUkAzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a374ac-3c51-463a-b1d4-f963b3d5fe17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/segment-anything.git"
      ],
      "metadata": {
        "id": "utjn-sV4elFN",
        "outputId": "fae5546e-5189-4dd8-dbe0-238e263b6b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-xropwl_6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-xropwl_6\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36586 sha256=ced4ab260741e5771d9e7b2c9b1f4094336a8215006fd97da5ef1c9c49a588e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c0obn5s4/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "LR60G0YWkCUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acf7ed4-16a7-45f9-b536-1f45e85feb1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"  # Replace with the URL of the file you want to download\n",
        "save_path = '/content/sam_vit_h_4b8939.pth'  # Replace with the desired path and file name to save\n",
        "\n",
        "urllib.request.urlretrieve(url, save_path)"
      ],
      "metadata": {
        "id": "G2hWDu6xep6m",
        "outputId": "738dc2fe-c277-43d7-81e8-d180bba6ccd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/sam_vit_h_4b8939.pth', <http.client.HTTPMessage at 0x78b23094c5b0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob\n",
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "from keras.utils import to_categorical\n",
        "from skimage.util import random_noise\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import label as nd_label\n",
        "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
        "import cv2\n",
        "from scipy.ndimage import generic_filter\n",
        "from keras.models import load_model\n",
        "from scipy.stats import mode\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from keras.utils import Sequence, to_categorical\n",
        "import rasterio.plot\n",
        "# Additional code can be added here if needed\n"
      ],
      "metadata": {
        "id": "ZaTY93f9kDxy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "# https://drive.google.com/file/d/1ozXL7HXqY7dLZP0Fxu6kyHiPcZJ4U4Rs/view?usp=drive_link\n",
        "url = 'https://drive.google.com/uc?id=1f4eGmykyiczmNz2VPeNNmQ7aC7q8N_hD'\n",
        "output = '/content/california_land_use.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "cwd = os.getcwd()\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cwd+'/sample_data/images')\n"
      ],
      "metadata": {
        "id": "UvOfZH5skF8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60abe13-86d4-4bba-cba6-d23acced6de1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f4eGmykyiczmNz2VPeNNmQ7aC7q8N_hD\n",
            "To: /content/california_land_use.zip\n",
            "100%|██████████| 2.76G/2.76G [00:30<00:00, 90.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from geotiff files\n",
        "def load_data(directory):\n",
        "    data = []\n",
        "    files = glob.glob(os.path.join(directory, \"*.tif\"))\n",
        "    for file in files:\n",
        "        with rasterio.open(file) as src:\n",
        "            band_data = []\n",
        "            for band in src.read():\n",
        "                band_data.append(band)\n",
        "            data.append(np.dstack(band_data))\n",
        "\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "rdqwV3yRO-p7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_reshape_image(image_path, img_height, img_width):\n",
        "    with rasterio.open(image_path) as src:\n",
        "        # Read the image data\n",
        "        image = src.read()\n",
        "        # Reshape the image\n",
        "        image = image.transpose((1, 2, 0))\n",
        "        # Resize image if necessary\n",
        "        if image.shape[0] != img_height or image.shape[1] != img_width:\n",
        "            image = cv2.resize(image, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
        "        # Ensure labels do not have an extra channel dimension\n",
        "        if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "            image = np.squeeze(image, axis=2)\n",
        "        return image"
      ],
      "metadata": {
        "id": "E1pu0sBVgv2h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(image_files, label_files, img_height, img_width, num_classes):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  image_files = glob.glob(os.path.join(image_files, \"*.tif\"))\n",
        "  for image_file in image_files:\n",
        "      image = load_and_reshape_image(image_file, img_height, img_width)\n",
        "      images.append(image)\n",
        "\n",
        "  label_files = glob.glob(os.path.join(label_files, \"*.tif\"))\n",
        "  for label_file in label_files:\n",
        "      label = load_and_reshape_image(label_file, img_height, img_width)\n",
        "      label -= 1  # adjust labels to be in the range 0-8 instead of 1-9\n",
        "      label = to_categorical(label, num_classes=9)   # one-hot encode the labels\n",
        "      labels.append(label)\n",
        "\n",
        "  return np.array(images), np.array(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "64_MmtZcgOmM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from keras.utils import Sequence, to_categorical\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, image_folder, label_folder, img_height, img_width, batch_size, num_classes, noise):\n",
        "        self.image_files = glob.glob(os.path.join(image_folder, \"*.tif\"))\n",
        "        self.label_files = glob.glob(os.path.join(label_folder, \"*.tif\"))\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_files = self.image_files[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        batch_images, batch_labels = self.load_images_and_labels(batch_files)\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def load_and_reshape_image(self, image_path):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            image = src.read()\n",
        "            image = image.transpose((1, 2, 0))\n",
        "            if image.shape[0] != self.img_height or image.shape[1] != self.img_width:\n",
        "                image = cv2.resize(image, (self.img_width, self.img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "                image = np.squeeze(image, axis=2)\n",
        "            if self.noise:\n",
        "                variance = np.var(image)\n",
        "                image = image*random_noise(image, mode='gaussian', var=variance)\n",
        "            return image\n",
        "\n",
        "    def load_images_and_labels(self, image_files):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image = self.load_and_reshape_image(image_file)\n",
        "            images.append(image)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            label_file = image_file.replace(\"rgbNIR\", \"labels\")\n",
        "            label = self.load_and_reshape_image(label_file)\n",
        "            label -= 1\n",
        "            label = to_categorical(label, num_classes=self.num_classes)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)\n"
      ],
      "metadata": {
        "id": "a6xCf9hzs2iK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size)  # Change the number of channels to 4\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])  # Use sparse categorical cross-entropy loss\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eLx0z59VPD8T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save_segments(input_folder, output_folder, model, img_height, img_width):\n",
        "      # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of input files\n",
        "    input_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
        "\n",
        "    for filename in input_files:\n",
        "              # Read input image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        with rasterio.open(image_path) as src:\n",
        "            # Read image data and reshape\n",
        "            image = src.read()  # Read all bands\n",
        "\n",
        "        image = load_and_reshape_image(image_path,img_height, img_width)\n",
        "        image = image.astype(np.uint8)\n",
        "        # print(image.shape)\n",
        "        masks = mask_generator.generate(image)\n",
        "\n",
        "        flat_mask = show_anns(masks)\n",
        "        imagery_file = rasterio.open(image_path)\n",
        "        imagery_transform = imagery_file.transform\n",
        "        reshaped_image = rasterio.plot.reshape_as_raster(flat_mask)\n",
        "        reshaped_image = reshaped_image[0]\n",
        "        # Get metadata from the input image\n",
        "        # print(reshaped_image.shape)\n",
        "        meta = src.meta\n",
        "\n",
        "        # Update metadata for the output image\n",
        "        meta.update(count=1, dtype=reshaped_image.dtype)\n",
        "\n",
        "        # Create output path\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Write all 9 prediction channels as separate bands\n",
        "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
        "            # for i in range(9):\n",
        "            dst.write(reshaped_image,1)  # Write each channel as a separate band\n",
        "\n",
        "        print(f\"Saved prediction for {filename}\")\n",
        "\n",
        "    print(\"Prediction and saving completed.\")"
      ],
      "metadata": {
        "id": "Z_ULG0KdpMh_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_save(input_folder, output_folder, model, img_height, img_width):\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get a list of input files\n",
        "    input_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
        "\n",
        "    for filename in input_files:\n",
        "        # Read input image\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        with rasterio.open(input_path) as src:\n",
        "            # Read image data and reshape\n",
        "            image = src.read()  # Read all bands\n",
        "            image = np.transpose(image, (1, 2, 0))  # Transpose to (height, width, bands)\n",
        "            image = cv2.resize(image, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
        "            image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "            # Perform prediction\n",
        "            prediction = model.predict(image)\n",
        "            prediction = prediction*255+1\n",
        "            prediction = prediction.astype(np.uint8)\n",
        "\n",
        "        # Get metadata from the input image\n",
        "        meta = src.meta\n",
        "\n",
        "        # Update metadata for the output image\n",
        "        meta.update(count=10, dtype=prediction.dtype,nodata = 0)\n",
        "        # meta.\n",
        "        # Create output path\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Write all 9 prediction channels as separate bands\n",
        "        with rasterio.open(output_path, 'w', **meta) as dst:\n",
        "            for i in range(9):\n",
        "                dst.write(prediction[0, :, :, i], i + 1)  # Write each channel as a separate band\n",
        "\n",
        "            # Add a 10th band containing the argmax of the 9 channels\n",
        "            argmax_band = np.argmax(prediction[0], axis=-1)\n",
        "            dst.write(argmax_band, 10)\n",
        "\n",
        "        print(f\"Saved prediction for {filename}\")\n",
        "\n",
        "    print(\"Prediction and saving completed.\")"
      ],
      "metadata": {
        "id": "6_qJQDGY7DSO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pred(pred):\n",
        "\n",
        "    def modal_filter(arr):\n",
        "      modes, counts = np.unique(arr, return_counts=True)\n",
        "      max_count_idx = np.argmax(counts)\n",
        "      return modes[max_count_idx]\n",
        "\n",
        "    pred = pred.astype(np.uint8)\n",
        "    # Converting input to 16 bit and replacing '0' values with 'nan'\n",
        "    pred = np.where(pred.astype(np.uint16) == 0, np.nan, pred)\n",
        "\n",
        "    # Create a mask of valid (non-NA) cells\n",
        "    valid_mask = ~np.isnan(pred)\n",
        "\n",
        "    # Compute the distance to the nearest valid cell for each cell\n",
        "    dist = ndimage.distance_transform_edt(~valid_mask, return_distances=False, return_indices=True)\n",
        "\n",
        "    # Assign the value of the nearest valid cell to each cell\n",
        "    pred_filled = pred[tuple(dist)]\n",
        "\n",
        "    # Create a mask for NA values after filling\n",
        "    na_mask = np.isnan(pred_filled)\n",
        "\n",
        "    # Create 2D structure for labeling\n",
        "    structure = np.ones((3, 3), dtype=bool)\n",
        "\n",
        "    # Label each separate cluster of NA values\n",
        "    labeled_mask, num_labels = nd_label(na_mask, structure=structure)\n",
        "\n",
        "    # Assign new values to each separate cluster\n",
        "    for label_num in range(1, num_labels + 1):\n",
        "        pred_filled[labeled_mask == label_num] = np.nanmax(pred_filled) + label_num\n",
        "\n",
        "    # Convert filled prediction to 8-bit\n",
        "    pred_filled = pred_filled.astype(np.uint8)\n",
        "\n",
        "    # Perform morphological opening operation to clean up small segments\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "    cleaned_pred = cv2.morphologyEx(pred_filled, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Apply modal filter using a sliding window approach\n",
        "    modal_filtered = np.zeros_like(cleaned_pred)\n",
        "    for i in range(1, cleaned_pred.shape[0] - 1):\n",
        "        for j in range(1, cleaned_pred.shape[1] - 1):\n",
        "            neighborhood = cleaned_pred[i-1:i+2, j-1:j+2]\n",
        "            modal_filtered[i, j] = modal_filter(neighborhood)\n",
        "\n",
        "    return modal_filtered"
      ],
      "metadata": {
        "id": "Iz3rQR6V6_u-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for i, ann in enumerate(sorted_anns):\n",
        "        m = ann['segmentation']\n",
        "        # color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        color_mask = i\n",
        "        img[m] = color_mask\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "8maGL45seCsQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_class_by_probability(pred, probability):\n",
        "    num_classes = probability.shape[-1]\n",
        "\n",
        "    # Create an array to store the assigned classes for each clump\n",
        "    assigned_classes = np.zeros_like(pred, dtype=np.uint8)\n",
        "\n",
        "    # Assign class based on mean probability for each clump\n",
        "    unique_labels = np.unique(pred)\n",
        "    for label in unique_labels:\n",
        "        if label != 0:\n",
        "            clump_mask = pred == label\n",
        "            clump_probabilities = probability[clump_mask]\n",
        "            clump_mean_probabilities = np.mean(clump_probabilities, axis=0)\n",
        "            assigned_class = np.argmax(clump_mean_probabilities) + 1\n",
        "            assigned_classes[pred == label] = assigned_class\n",
        "\n",
        "    return assigned_classes"
      ],
      "metadata": {
        "id": "XT8Ng0ecg2LP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(img_size = (640,640,3),num_classes =9)"
      ],
      "metadata": {
        "id": "lUA1fVZ0PE7M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_image_folder = \"/content/sample_data/images/training/rgbNIR\"  # Replace with your image folder path\n",
        "training_label_folder = \"/content/sample_data/images/training/labels\"  # Replace with your label folder path\n",
        "\n",
        "validation_image_folder = \"/content/sample_data/images/validation/rgbNIR\"  # Replace with your image folder path\n",
        "validation_label_folder = \"/content/sample_data/images/validation/labels\"  # Replace with your label folder path\n",
        "\n",
        "\n",
        "img_height = 640  # Set your desired image height\n",
        "img_width = 640  # Set your desired image width\n",
        "batch_size = 16  # Set your desired batch size\n",
        "num_classes = 9  # Set the number of classes for one-hot encoding\n",
        "\n",
        "# Create the data generator\n",
        "training_data_generator = DataGenerator(training_image_folder, training_label_folder, img_height, img_width, batch_size, num_classes,True)\n",
        "validation_data_generator = DataGenerator(validation_image_folder, validation_label_folder, img_height, img_width, batch_size, num_classes,False)\n"
      ],
      "metadata": {
        "id": "pUETvWhVyFHL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from memory\n",
        "# model = load_model('/content/drive/MyDrive/Colab_Demo/landcover_model.h5')\n",
        "# validation_data_generator(1)"
      ],
      "metadata": {
        "id": "2wC2pZdgjdru"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_data_generator[1][1]"
      ],
      "metadata": {
        "id": "Poi7_EovuV8c"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"landcover_segmentation.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(training_data_generator, validation_data=validation_data_generator, epochs=100, callbacks=callbacks)\n",
        "# model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=10)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(training_data_generator, validation_data=validation_data_generator, epochs=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(validation_data_generator)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n",
        "model.fit(training_generator, validation_data=validation_generator, epochs=100)"
      ],
      "metadata": {
        "id": "eA01SHvOQ1gJ",
        "outputId": "b5dca1f8-4553-4510-a213-30c509a8e661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 9/87 [==>...........................] - ETA: 2:27 - loss: 4.6720 - accuracy: 0.4457"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "sam = sam_model_registry[\"vit_h\"](checkpoint= '/content/sam_vit_h_4b8939.pth' )\n",
        "sam.to(device=device)"
      ],
      "metadata": {
        "id": "5ijKGjdHey9V",
        "outputId": "78c27701-6263-4adb-edae-5da9e02e146b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sam(\n",
              "  (image_encoder): ImageEncoderViT(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0-31): 32 x Block(\n",
              "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): MLPBlock(\n",
              "          (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (neck): Sequential(\n",
              "      (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): LayerNorm2d()\n",
              "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (3): LayerNorm2d()\n",
              "    )\n",
              "  )\n",
              "  (prompt_encoder): PromptEncoder(\n",
              "    (pe_layer): PositionEmbeddingRandom()\n",
              "    (point_embeddings): ModuleList(\n",
              "      (0-3): 4 x Embedding(1, 256)\n",
              "    )\n",
              "    (not_a_point_embed): Embedding(1, 256)\n",
              "    (mask_downscaling): Sequential(\n",
              "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (1): LayerNorm2d()\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (4): LayerNorm2d()\n",
              "      (5): GELU(approximate='none')\n",
              "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (no_mask_embed): Embedding(1, 256)\n",
              "  )\n",
              "  (mask_decoder): MaskDecoder(\n",
              "    (transformer): TwoWayTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x TwoWayAttentionBlock(\n",
              "          (self_attn): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (cross_attn_token_to_image): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "            (act): ReLU()\n",
              "          )\n",
              "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (cross_attn_image_to_token): Attention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_attn_token_to_image): Attention(\n",
              "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "      )\n",
              "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (iou_token): Embedding(1, 256)\n",
              "    (mask_tokens): Embedding(4, 256)\n",
              "    (output_upscaling): Sequential(\n",
              "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (1): LayerNorm2d()\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (4): GELU(approximate='none')\n",
              "    )\n",
              "    (output_hypernetworks_mlps): ModuleList(\n",
              "      (0-3): 4 x MLP(\n",
              "        (layers): ModuleList(\n",
              "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (iou_prediction_head): MLP(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
              "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_generator = SamAutomaticMaskGenerator(model=sam,\n",
        "                                           points_per_side=32,\n",
        "                                           pred_iou_thresh=0.8,\n",
        "                                           stability_score_thresh=0.8,\n",
        "                                           crop_n_layers=1,\n",
        "                                           crop_n_points_downscale_factor=2,\n",
        "                                           min_mask_region_area=200,  # Requires open-cv to run post-processing\n",
        "                                           )"
      ],
      "metadata": {
        "id": "9VlV_Pbie4IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " predict_and_save_segments('/content/sample_data/images', '/content/drive/MyDrive/Colab_Demo/Murrieta_Result_2/Segments/', model, img_height, img_width)"
      ],
      "metadata": {
        "id": "XiFzc_OvqQH-",
        "outputId": "211f6307-ea92-4de3-87f6-5096f56fce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved prediction for 8_5.tif\n",
            "Saved prediction for 2_4.tif\n",
            "Saved prediction for 12_16.tif\n",
            "Saved prediction for 16_6.tif\n",
            "Saved prediction for 4_16.tif\n",
            "Saved prediction for 8_3.tif\n",
            "Saved prediction for 8_7.tif\n",
            "Saved prediction for 13_6.tif\n",
            "Saved prediction for 7_10.tif\n",
            "Saved prediction for 9_5.tif\n",
            "Saved prediction for 9_18.tif\n",
            "Saved prediction for 1_8.tif\n",
            "Saved prediction for 13_15.tif\n",
            "Saved prediction for 9_12.tif\n",
            "Saved prediction for 7_7.tif\n",
            "Saved prediction for 6_7.tif\n",
            "Saved prediction for 4_4.tif\n",
            "Saved prediction for 16_2.tif\n",
            "Saved prediction for 5_18.tif\n",
            "Saved prediction for 8_11.tif\n",
            "Saved prediction for 6_10.tif\n",
            "Saved prediction for 1_10.tif\n",
            "Saved prediction for 3_11.tif\n",
            "Saved prediction for 4_2.tif\n",
            "Saved prediction for 3_14.tif\n",
            "Saved prediction for 10_18.tif\n",
            "Saved prediction for 16_13.tif\n",
            "Saved prediction for 11_7.tif\n",
            "Saved prediction for 16_5.tif\n",
            "Saved prediction for 5_2.tif\n",
            "Saved prediction for 11_1.tif\n",
            "Saved prediction for 8_13.tif\n",
            "Saved prediction for 3_13.tif\n",
            "Saved prediction for 5_9.tif\n",
            "Saved prediction for 16_17.tif\n",
            "Saved prediction for 15_17.tif\n",
            "Saved prediction for 15_1.tif\n",
            "Saved prediction for 2_16.tif\n",
            "Saved prediction for 7_15.tif\n",
            "Saved prediction for 9_7.tif\n",
            "Saved prediction for 7_13.tif\n",
            "Saved prediction for 9_14.tif\n",
            "Saved prediction for 5_1.tif\n",
            "Saved prediction for 6_13.tif\n",
            "Saved prediction for 16_18.tif\n",
            "Saved prediction for 10_13.tif\n",
            "Saved prediction for 11_10.tif\n",
            "Saved prediction for 2_10.tif\n",
            "Saved prediction for 3_6.tif\n",
            "Saved prediction for 3_15.tif\n",
            "Saved prediction for 6_18.tif\n",
            "Saved prediction for 11_14.tif\n",
            "Saved prediction for 16_9.tif\n",
            "Saved prediction for 7_12.tif\n",
            "Saved prediction for 14_2.tif\n",
            "Saved prediction for 11_9.tif\n",
            "Saved prediction for 12_8.tif\n",
            "Saved prediction for 15_9.tif\n",
            "Saved prediction for 5_17.tif\n",
            "Saved prediction for 7_4.tif\n",
            "Saved prediction for 11_16.tif\n",
            "Saved prediction for 1_4.tif\n",
            "Saved prediction for 2_15.tif\n",
            "Saved prediction for 10_9.tif\n",
            "Saved prediction for 12_1.tif\n",
            "Saved prediction for 4_10.tif\n",
            "Saved prediction for 4_6.tif\n",
            "Saved prediction for 1_3.tif\n",
            "Saved prediction for 1_16.tif\n",
            "Saved prediction for 1_2.tif\n",
            "Saved prediction for 4_13.tif\n",
            "Saved prediction for 14_5.tif\n",
            "Saved prediction for 9_17.tif\n",
            "Saved prediction for 11_3.tif\n",
            "Saved prediction for 3_9.tif\n",
            "Saved prediction for 15_16.tif\n",
            "Saved prediction for 14_13.tif\n",
            "Saved prediction for 12_15.tif\n",
            "Saved prediction for 9_10.tif\n",
            "Saved prediction for 15_5.tif\n",
            "Saved prediction for 12_2.tif\n",
            "Saved prediction for 5_4.tif\n",
            "Saved prediction for 2_1.tif\n",
            "Saved prediction for 8_12.tif\n",
            "Saved prediction for 2_18.tif\n",
            "Saved prediction for 8_14.tif\n",
            "Saved prediction for 8_8.tif\n",
            "Saved prediction for 13_18.tif\n",
            "Saved prediction for 4_1.tif\n",
            "Saved prediction for 11_11.tif\n",
            "Saved prediction for 8_2.tif\n",
            "Saved prediction for 4_8.tif\n",
            "Saved prediction for 3_16.tif\n",
            "Saved prediction for 8_16.tif\n",
            "Saved prediction for 12_6.tif\n",
            "Saved prediction for 16_8.tif\n",
            "Saved prediction for 6_4.tif\n",
            "Saved prediction for 16_15.tif\n",
            "Saved prediction for 6_11.tif\n",
            "Saved prediction for 7_14.tif\n",
            "Saved prediction for 4_5.tif\n",
            "Saved prediction for 11_5.tif\n",
            "Saved prediction for 7_17.tif\n",
            "Saved prediction for 9_6.tif\n",
            "Saved prediction for 9_15.tif\n",
            "Saved prediction for 11_15.tif\n",
            "Saved prediction for 6_14.tif\n",
            "Saved prediction for 12_11.tif\n",
            "Saved prediction for 15_6.tif\n",
            "Saved prediction for 3_18.tif\n",
            "Saved prediction for 12_13.tif\n",
            "Saved prediction for 9_13.tif\n",
            "Saved prediction for 4_15.tif\n",
            "Saved prediction for 8_9.tif\n",
            "Saved prediction for 16_4.tif\n",
            "Saved prediction for 11_4.tif\n",
            "Saved prediction for 7_18.tif\n",
            "Saved prediction for 13_3.tif\n",
            "Saved prediction for 14_3.tif\n",
            "Saved prediction for 13_8.tif\n",
            "Saved prediction for 4_17.tif\n",
            "Saved prediction for 2_5.tif\n",
            "Saved prediction for 15_4.tif\n",
            "Saved prediction for 8_1.tif\n",
            "Saved prediction for 14_15.tif\n",
            "Saved prediction for 6_6.tif\n",
            "Saved prediction for 15_8.tif\n",
            "Saved prediction for 16_12.tif\n",
            "Saved prediction for 13_10.tif\n",
            "Saved prediction for 14_17.tif\n",
            "Saved prediction for 6_3.tif\n",
            "Saved prediction for 5_10.tif\n",
            "Saved prediction for 16_7.tif\n",
            "Saved prediction for 10_2.tif\n",
            "Saved prediction for 1_7.tif\n",
            "Saved prediction for 4_7.tif\n",
            "Saved prediction for 5_15.tif\n",
            "Saved prediction for 10_10.tif\n",
            "Saved prediction for 12_17.tif\n",
            "Saved prediction for 12_7.tif\n",
            "Saved prediction for 4_11.tif\n",
            "Saved prediction for 4_14.tif\n",
            "Saved prediction for 13_12.tif\n",
            "Saved prediction for 12_18.tif\n",
            "Saved prediction for 3_1.tif\n",
            "Saved prediction for 1_18.tif\n",
            "Saved prediction for 14_8.tif\n",
            "Saved prediction for 14_6.tif\n",
            "Saved prediction for 1_15.tif\n",
            "Saved prediction for 13_5.tif\n",
            "Saved prediction for 16_14.tif\n",
            "Saved prediction for 15_3.tif\n",
            "Saved prediction for 14_10.tif\n",
            "Saved prediction for 9_11.tif\n",
            "Saved prediction for 1_6.tif\n",
            "Saved prediction for 5_5.tif\n",
            "Saved prediction for 16_16.tif\n",
            "Saved prediction for 6_17.tif\n",
            "Saved prediction for 6_1.tif\n",
            "Saved prediction for 1_9.tif\n",
            "Saved prediction for 2_17.tif\n",
            "Saved prediction for 3_10.tif\n",
            "Saved prediction for 7_8.tif\n",
            "Saved prediction for 10_1.tif\n",
            "Saved prediction for 15_15.tif\n",
            "Saved prediction for 1_12.tif\n",
            "Saved prediction for 10_12.tif\n",
            "Saved prediction for 1_5.tif\n",
            "Saved prediction for 12_3.tif\n",
            "Saved prediction for 14_14.tif\n",
            "Saved prediction for 10_17.tif\n",
            "Saved prediction for 10_7.tif\n",
            "Saved prediction for 13_4.tif\n",
            "Saved prediction for 16_10.tif\n",
            "Saved prediction for 13_14.tif\n",
            "Saved prediction for 1_11.tif\n",
            "Saved prediction for 10_3.tif\n",
            "Saved prediction for 10_15.tif\n",
            "Saved prediction for 2_11.tif\n",
            "Saved prediction for 13_2.tif\n",
            "Saved prediction for 11_12.tif\n",
            "Saved prediction for 3_3.tif\n",
            "Saved prediction for 14_9.tif\n",
            "Saved prediction for 2_2.tif\n",
            "Saved prediction for 5_14.tif\n",
            "Saved prediction for 13_7.tif\n",
            "Saved prediction for 8_10.tif\n",
            "Saved prediction for 7_2.tif\n",
            "Saved prediction for 2_8.tif\n",
            "Saved prediction for 3_2.tif\n",
            "Saved prediction for 9_9.tif\n",
            "Saved prediction for 6_9.tif\n",
            "Saved prediction for 8_15.tif\n",
            "Saved prediction for 7_11.tif\n",
            "Saved prediction for 6_8.tif\n",
            "Saved prediction for 8_4.tif\n",
            "Saved prediction for 12_5.tif\n",
            "Saved prediction for 15_18.tif\n",
            "Saved prediction for 2_9.tif\n",
            "Saved prediction for 8_18.tif\n",
            "Saved prediction for 5_6.tif\n",
            "Saved prediction for 3_7.tif\n",
            "Saved prediction for 13_11.tif\n",
            "Saved prediction for 3_17.tif\n",
            "Saved prediction for 11_18.tif\n",
            "Saved prediction for 3_5.tif\n",
            "Saved prediction for 10_8.tif\n",
            "Saved prediction for 8_6.tif\n",
            "Saved prediction for 10_5.tif\n",
            "Saved prediction for 8_17.tif\n",
            "Saved prediction for 6_12.tif\n",
            "Saved prediction for 14_1.tif\n",
            "Saved prediction for 13_1.tif\n",
            "Saved prediction for 4_3.tif\n",
            "Saved prediction for 5_11.tif\n",
            "Saved prediction for 10_4.tif\n",
            "Saved prediction for 7_16.tif\n",
            "Saved prediction for 5_13.tif\n",
            "Saved prediction for 3_8.tif\n",
            "Saved prediction for 5_3.tif\n",
            "Saved prediction for 1_13.tif\n",
            "Saved prediction for 14_16.tif\n",
            "Saved prediction for 10_11.tif\n",
            "Saved prediction for 9_8.tif\n",
            "Saved prediction for 9_4.tif\n",
            "Saved prediction for 7_1.tif\n",
            "Saved prediction for 13_16.tif\n",
            "Saved prediction for 2_12.tif\n",
            "Saved prediction for 11_6.tif\n",
            "Saved prediction for 11_8.tif\n",
            "Saved prediction for 7_6.tif\n",
            "Saved prediction for 5_12.tif\n",
            "Saved prediction for 13_13.tif\n",
            "Saved prediction for 14_12.tif\n",
            "Saved prediction for 1_1.tif\n",
            "Saved prediction for 15_12.tif\n",
            "Saved prediction for 11_17.tif\n",
            "Saved prediction for 9_16.tif\n",
            "Saved prediction for 6_16.tif\n",
            "Saved prediction for 7_9.tif\n",
            "Saved prediction for 14_11.tif\n",
            "Saved prediction for 3_4.tif\n",
            "Saved prediction for 1_17.tif\n",
            "Saved prediction for 2_3.tif\n",
            "Saved prediction for 4_12.tif\n",
            "Saved prediction for 12_12.tif\n",
            "Saved prediction for 10_16.tif\n",
            "Saved prediction for 6_15.tif\n",
            "Saved prediction for 9_1.tif\n",
            "Saved prediction for 2_14.tif\n",
            "Saved prediction for 3_12.tif\n",
            "Saved prediction for 12_4.tif\n",
            "Saved prediction for 13_17.tif\n",
            "Saved prediction for 14_18.tif\n",
            "Saved prediction for 14_7.tif\n",
            "Saved prediction for 11_2.tif\n",
            "Saved prediction for 2_6.tif\n",
            "Saved prediction for 4_9.tif\n",
            "Saved prediction for 11_13.tif\n",
            "Saved prediction for 12_9.tif\n",
            "Saved prediction for 15_7.tif\n",
            "Saved prediction for 16_11.tif\n",
            "Saved prediction for 16_1.tif\n",
            "Saved prediction for 15_13.tif\n",
            "Saved prediction for 9_3.tif\n",
            "Saved prediction for 12_14.tif\n",
            "Saved prediction for 13_9.tif\n",
            "Saved prediction for 15_14.tif\n",
            "Saved prediction for 9_2.tif\n",
            "Saved prediction for 15_2.tif\n",
            "Saved prediction for 4_18.tif\n",
            "Saved prediction for 1_14.tif\n",
            "Saved prediction for 15_11.tif\n",
            "Saved prediction for 2_13.tif\n",
            "Saved prediction for 10_6.tif\n",
            "Saved prediction for 5_16.tif\n",
            "Saved prediction for 6_2.tif\n",
            "Saved prediction for 15_10.tif\n",
            "Saved prediction for 5_8.tif\n",
            "Saved prediction for 16_3.tif\n",
            "Saved prediction for 2_7.tif\n",
            "Saved prediction for 5_7.tif\n",
            "Saved prediction for 7_3.tif\n",
            "Saved prediction for 10_14.tif\n",
            "Saved prediction for 7_5.tif\n",
            "Saved prediction for 12_10.tif\n",
            "Saved prediction for 14_4.tif\n",
            "Saved prediction for 6_5.tif\n",
            "Prediction and saving completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_save('/content/sample_data/images', '/content/drive/MyDrive/Colab_Demo/Murrieta_Result_2/Predictions', model, 640, 640)"
      ],
      "metadata": {
        "id": "xdLsikOSl1tw",
        "outputId": "4de17c2a-323d-4db2-be2d-69721d4a01e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 8_5.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 2_4.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 12_16.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16_6.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 4_16.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 8_3.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 8_7.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 13_6.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 7_10.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 9_5.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 9_18.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 1_8.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 13_15.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 9_12.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 7_7.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 6_7.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 4_4.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16_2.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 5_18.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 8_11.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 6_10.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 1_10.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 3_11.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 4_2.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 3_14.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 10_18.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 16_13.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 11_7.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 16_5.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 5_2.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 11_1.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8_13.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 3_13.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 5_9.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16_17.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 15_17.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 15_1.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 2_16.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_15.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_13.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 9_14.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 5_1.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 6_13.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_18.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 10_13.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11_10.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 2_10.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 3_6.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 3_15.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 6_18.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11_14.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 7_12.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 14_2.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 11_9.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_8.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 15_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 5_17.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 11_16.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 1_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_15.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 10_9.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_1.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 4_10.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 4_6.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 1_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_2.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_13.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14_5.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_17.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 3_9.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 15_16.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 14_13.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 12_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_10.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_5.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 12_2.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_4.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 2_1.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8_12.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 2_18.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8_14.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_18.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 4_1.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 11_11.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8_2.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_8.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 3_16.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 8_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 16_8.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 6_4.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 16_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_11.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 7_14.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 4_5.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 11_5.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 7_17.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_15.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 11_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_14.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_6.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 3_18.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12_13.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 9_13.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_4.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 11_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7_18.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_3.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14_3.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 13_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_17.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 2_5.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 15_4.tif\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Saved prediction for 8_1.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 14_15.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 6_6.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 15_8.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 16_12.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 13_10.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 14_17.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 6_3.tif\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Saved prediction for 5_10.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 16_7.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 10_2.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 1_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 4_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 5_15.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 10_10.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 12_17.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 12_7.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_14.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_18.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 3_1.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 1_18.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14_8.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14_6.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 1_15.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 13_5.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_14.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14_10.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_5.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_17.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_1.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 2_17.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 3_10.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_1.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_12.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10_12.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 1_5.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 12_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14_14.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 10_17.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_7.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 16_10.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_14.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 1_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_3.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 10_15.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_2.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 11_12.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 3_3.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 14_9.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 2_2.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 5_14.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8_10.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_2.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 2_8.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 3_2.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 9_9.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 6_9.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 8_15.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 7_11.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 6_8.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 8_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_5.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 15_18.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 2_9.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 8_18.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 5_6.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 3_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 13_11.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 3_17.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 11_18.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 3_5.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 10_8.tif\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Saved prediction for 8_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_5.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 8_17.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 6_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14_1.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_1.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 4_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_11.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 10_4.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 7_16.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 5_13.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 3_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_13.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 14_16.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 10_11.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 9_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_4.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 7_1.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 13_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_12.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 11_6.tif\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Saved prediction for 11_8.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7_6.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 5_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_13.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 1_1.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 11_17.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 9_16.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 6_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 7_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 14_11.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 3_4.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 1_17.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_3.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 4_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_12.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_15.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 9_1.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 2_14.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 3_12.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 12_4.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 13_17.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14_18.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 14_7.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 11_2.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 2_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_9.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 11_13.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 12_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 15_7.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 16_11.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 16_1.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15_13.tif\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Saved prediction for 9_3.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 12_14.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 13_9.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 15_14.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 9_2.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15_2.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 4_18.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 1_14.tif\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Saved prediction for 15_11.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_13.tif\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Saved prediction for 10_6.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_16.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 6_2.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 15_10.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 5_8.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 16_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 2_7.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 5_7.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_3.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 10_14.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 7_5.tif\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Saved prediction for 12_10.tif\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Saved prediction for 14_4.tif\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Saved prediction for 6_5.tif\n",
            "Prediction and saving completed.\n"
          ]
        }
      ]
    }
  ]
}