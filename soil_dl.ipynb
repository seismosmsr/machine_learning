{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/soil_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJSR_lUJAuGW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfASAHA7B1a0",
        "outputId": "54730f8e-c2e8-4339-c25f-319dbc6a3d0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "FUiG_4XBCkTW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/sequence_data.csv'"
      ],
      "metadata": {
        "id": "46NsUEt2B80A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drivers_gpd = gpd.read_file('/content/drive/MyDrive/hawaii_soils/Analysis Data/250_summary_grid_dt.gpkg')"
      ],
      "metadata": {
        "id": "PcbyIy1MCszn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soils_csv = gpd.read_file('/content/drive/MyDrive/hawaii_soils/HI soils data/combined_soc_2024_04_05.csv')"
      ],
      "metadata": {
        "id": "4T2wvedGC1aG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import Point\n",
        "\n",
        "soils_csv = soils_csv[(soils_csv['latitude'] != '') & (soils_csv['longitude'] != '')]\n",
        "soils_csv['geometry'] = soils_csv.apply(lambda row: Point(float(row['longitude']), float(row['latitude'] )), axis=1)\n",
        "soils_gpd = gpd.GeoDataFrame(soils_csv, geometry='geometry', crs=\"EPSG:4326\")"
      ],
      "metadata": {
        "id": "VHIQgCCiD1le"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Ensure both GeoDataFrames have the same CRS\n",
        "soils_gpd = soils_gpd.to_crs(drivers_gpd.crs)\n",
        "\n",
        "# Perform spatial join\n",
        "matched_data = gpd.sjoin_nearest(soils_gpd, drivers_gpd, how='left', distance_col='distance')"
      ],
      "metadata": {
        "id": "GUDqgLj2FDfT"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply a buffer to each geometry in one of the GeoDataFrames (e.g., soils_gpd)\n",
        "soils_buffered = soils_gpd.copy()\n",
        "\n",
        "soils_buffered.geometry = soils_buffered.to_crs(epsg=32604).geometry.buffer(1000).to_crs('ESRI:102261')\n",
        "\n",
        "# soils_gpd = soils_gpd\n",
        "# Step 2: Spatial Join\n",
        "# Perform a spatial join with the buffered GeoDataFrame\n",
        "# This finds all drivers_gpd points that fall within the 10,000-meter buffer of any point in soils_gpd\n",
        "matches_within_distance = gpd.sjoin(soils_buffered, drivers_gpd, how='left', op='intersects')\n"
      ],
      "metadata": {
        "id": "d7TjwVCOXV91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7f9e95-576b-4465-d0bd-9c72fb2585d5"
      },
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(soils_gpd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTb45YdE1uAy",
        "outputId": "e089a11c-3b56-4559-91ec-0b98231e37da"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6842"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(soils_gpd['unique_id'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVWWzdTk18Dx",
        "outputId": "f8fcc894-4ae2-4289-f46e-b60b5d6716fa"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6842"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reserve_data = matches_within_distance.groupby('unique_id').sample(n=1)"
      ],
      "metadata": {
        "id": "t1t6g24EXvKP"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Group by 'unique_id' and sample one row from each group\n",
        "matched_data = matches_within_distance.groupby('unique_id').sample(n=1)\n",
        "\n",
        "# # Reset index if you want a clean DataFrame index\n",
        "matched_data = matched_data.reset_index(drop=True)\n",
        "matched_data['distance'] = 0"
      ],
      "metadata": {
        "id": "O921-2vX2wS3"
      },
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matched_data = unique_sample"
      ],
      "metadata": {
        "id": "ovs1OeKY25bD"
      },
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rows = matched_data[matched_data[\"depth_adj_bottom\"] == '20']\n",
        "unique_rows = unique_rows.drop_duplicates(subset=['latitude', 'longitude'])\n",
        "unique_rows = unique_rows[unique_rows['distance'] < 251]\n",
        "matched_data = unique_rows"
      ],
      "metadata": {
        "id": "DKvp_WkRIRj_"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_data['imp_c_float'] = [float(datum) for datum in matched_data['imp_c']]\n",
        "# matches_within_10000['imp_c_float'] = [float(datum) for datum in matches_within_10000['imp_c']]"
      ],
      "metadata": {
        "id": "efng2Ra9Ho9l"
      },
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaled_numeric_df"
      ],
      "metadata": {
        "id": "IxCdEWnG6Uup"
      },
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "id_fields = matched_data[['source_dataset', 'island', 'soil_column_id', 'unique_id', 'depth_top', 'depth_bottom', 'depth_adj_bottom', 'latitude', 'longitude']]\n",
        "\n",
        "keep_cols = [21,22,23,24,25,26,27,28, 29, 31,32, 33,34,36,36,37,38,39,40,41,42,43,44,45,46,47, 48, 55]\n",
        "# Select only numeric columns\n",
        "numeric_cols = matched_data.iloc[:,keep_cols]\n",
        "numeric_cols.replace('', np.nan, inplace=True)\n",
        "numeric_cols = numeric_cols.astype(float)\n",
        "numeric_cols.fillna(0, inplace=True)\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler ()\n",
        "\n",
        "# Fit the scaler on the numeric columns\n",
        "scaler.fit(numeric_cols)\n",
        "\n",
        "# Transform the numeric columns\n",
        "scaled_numeric_cols = scaler.transform(numeric_cols)\n",
        "\n",
        "# Convert the scaled numeric columns back to a DataFrame\n",
        "scaled_numeric_df = pd.DataFrame(scaled_numeric_cols, columns=numeric_cols.columns, index=numeric_cols.index)\n",
        "\n",
        "# scaled_numeric_df = scaled_numeric_df\n",
        "# Concatenate the ID fields back with the numeric columns\n",
        "numeric_df = pd.concat([id_fields, scaled_numeric_df], axis=1)"
      ],
      "metadata": {
        "id": "Lzlo7QYVFXwo",
        "outputId": "4324af8c-39e8-445d-88be-1ec91dd2bcbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-493-7306ae049bea>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  numeric_cols.replace('', np.nan, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_numeric_df.columns"
      ],
      "metadata": {
        "id": "eYnAyM2LsFQc",
        "outputId": "7fadc3af-544b-41c5-f98f-239672abb589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['water', 'trees', 'grass', 'flooded_vegetation', 'crops',\n",
              "       'shrub_and_scrub', 'built', 'bare', 'snow_and_ice', 'elevation',\n",
              "       'landform', 'SRTM_mTPI', 'aet', 'pdsi', 'pdsi', 'pet', 'pr', 'ro',\n",
              "       'soil', 'srad', 'swe', 'tmmn', 'tmmx', 'vap', 'vpd', 'vs', 'agbd_m',\n",
              "       'imp_c_float'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def real_sequence_generator(data, batch_size):\n",
        "    while True:\n",
        "        # Shuffle the data at the beginning of each epoch\n",
        "        np.random.shuffle(data)\n",
        "        for i in range(0, len(data), batch_size):\n",
        "            batch = data[i:i + batch_size]\n",
        "            # If the batch is smaller than the batch size, pad it with samples from the beginning\n",
        "            if len(batch) < batch_size:\n",
        "                padding = data[:(batch_size - len(batch))]\n",
        "                batch = np.concatenate([batch, padding], axis=0)\n",
        "            # Separate the input and output sequences\n",
        "            input_sequences = batch[:, :-1]  # First 3 elements as input\n",
        "            output_sequences = batch[:, -1]  # Last element as output\n",
        "            yield input_sequences, output_sequences\n",
        "\n",
        "\n",
        "train_sequences, val_sequences = train_test_split(scaled_numeric_cols, test_size=0.2, random_state=42)\n",
        "\n",
        "test_sequences, val_sequences = train_test_split(val_sequences, test_size=0.5, random_state=42)\n",
        "\n",
        "batch_size = 128  # Set the batch size\n",
        "\n",
        "\n",
        "# Define the training and validation generators\n",
        "train_gen = real_sequence_generator(train_sequences, batch_size)\n",
        "test_gen = real_sequence_generator(test_sequences, batch_size)\n",
        "val_gen = real_sequence_generator(val_sequences, batch_size)\n"
      ],
      "metadata": {
        "id": "YONOBC-8BSw2"
      },
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_numeric_df.to_csv('scaled_df.csv')"
      ],
      "metadata": {
        "id": "OnbqvkDaD6J6"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator model\n",
        "def build_model(input_sequence_shape, output_sequence_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(256, activation='relu', input_dim=input_sequence_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),  # Dropout layer after the first LeakyReLU\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(output_sequence_shape, activation='linear')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Oc8rt5XeQkXF"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "XI3i0e0HIRVR"
      },
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the last column is the target variable\n",
        "X = scaled_numeric_df.iloc[:, :-1]\n",
        "y = scaled_numeric_df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nuNdmUpFNREb"
      },
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential([\n",
        "#     Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "\n",
        "#     Dense(32, activation='relu'),\n",
        "#     Dense(1, activation='linear')  # Change activation if it's a classification problem\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "YrKyetqsNeFO"
      },
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soc_model = build_model(27,1)"
      ],
      "metadata": {
        "id": "I4H04CPiUPOm"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soc_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')  # Change loss if it's a classification problem\n"
      ],
      "metadata": {
        "id": "y1ujeqVVNfLa"
      },
      "execution_count": 502,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = soc_model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AHz825y_8j4",
        "outputId": "123b918b-3bc7-4c25-a2a8-03e0c94130c3"
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 72ms/step - loss: 2.6966 - val_loss: 0.0454\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.3506 - val_loss: 0.0422\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 2.5095 - val_loss: 0.0374\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4256 - val_loss: 0.0308\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.6778 - val_loss: 0.0331\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.4286 - val_loss: 0.0341\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.9676 - val_loss: 0.0323\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.2403 - val_loss: 0.0333\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.3583 - val_loss: 0.0352\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.0738 - val_loss: 0.0322\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.2884 - val_loss: 0.0372\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.8221 - val_loss: 0.0336\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.4869 - val_loss: 0.0337\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 1.0208 - val_loss: 0.0331\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8890 - val_loss: 0.0303\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8345 - val_loss: 0.0350\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8548 - val_loss: 0.0358\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6209 - val_loss: 0.0320\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9116 - val_loss: 0.0314\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7672 - val_loss: 0.0286\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.9136 - val_loss: 0.0262\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.7182 - val_loss: 0.0303\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5448 - val_loss: 0.0310\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3962 - val_loss: 0.0299\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6698 - val_loss: 0.0310\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5447 - val_loss: 0.0324\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5076 - val_loss: 0.0306\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5394 - val_loss: 0.0264\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6089 - val_loss: 0.0285\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4186 - val_loss: 0.0286\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5258 - val_loss: 0.0261\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3664 - val_loss: 0.0262\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4762 - val_loss: 0.0282\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3919 - val_loss: 0.0273\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5068 - val_loss: 0.0263\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3539 - val_loss: 0.0216\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3831 - val_loss: 0.0204\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5777 - val_loss: 0.0262\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4763 - val_loss: 0.0266\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3655 - val_loss: 0.0200\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4604 - val_loss: 0.0227\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4630 - val_loss: 0.0308\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3909 - val_loss: 0.0222\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3304 - val_loss: 0.0203\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2392 - val_loss: 0.0228\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2885 - val_loss: 0.0284\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2950 - val_loss: 0.0267\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2834 - val_loss: 0.0228\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2121 - val_loss: 0.0236\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2566 - val_loss: 0.0243\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2496 - val_loss: 0.0268\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2020 - val_loss: 0.0283\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3257 - val_loss: 0.0254\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2659 - val_loss: 0.0230\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1430 - val_loss: 0.0259\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1974 - val_loss: 0.0263\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2529 - val_loss: 0.0215\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2071 - val_loss: 0.0211\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2833 - val_loss: 0.0266\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2354 - val_loss: 0.0245\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2325 - val_loss: 0.0230\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1722 - val_loss: 0.0233\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2030 - val_loss: 0.0236\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2046 - val_loss: 0.0277\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2099 - val_loss: 0.0250\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1385 - val_loss: 0.0236\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1227 - val_loss: 0.0249\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1107 - val_loss: 0.0263\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1669 - val_loss: 0.0263\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1806 - val_loss: 0.0284\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2068 - val_loss: 0.0215\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1350 - val_loss: 0.0266\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1461 - val_loss: 0.0260\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1167 - val_loss: 0.0232\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1205 - val_loss: 0.0223\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1307 - val_loss: 0.0222\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1155 - val_loss: 0.0227\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1957 - val_loss: 0.0261\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1912 - val_loss: 0.0183\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1197 - val_loss: 0.0206\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1442 - val_loss: 0.0209\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1112 - val_loss: 0.0198\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1252 - val_loss: 0.0197\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1313 - val_loss: 0.0205\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1499 - val_loss: 0.0193\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1251 - val_loss: 0.0199\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0843 - val_loss: 0.0339\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1055 - val_loss: 0.0226\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0906 - val_loss: 0.0179\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0963 - val_loss: 0.0211\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1064 - val_loss: 0.0186\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1042 - val_loss: 0.0385\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1191 - val_loss: 0.0697\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1350 - val_loss: 0.0195\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1027 - val_loss: 0.0269\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1544 - val_loss: 0.0170\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0993 - val_loss: 0.0201\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0795 - val_loss: 0.0349\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0841 - val_loss: 0.0175\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1001 - val_loss: 0.0186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soc_model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')  # Change loss if it's a classification problem\n"
      ],
      "metadata": {
        "id": "TRkrBd5a_-_B"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = soc_model.fit(X_train, y_train, validation_split=0.2, epochs=300, batch_size=128, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtVY6LD_8L7",
        "outputId": "29926004-2f70-4b81-89a1-bba70e54db08"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 2s 74ms/step - loss: 0.0927 - val_loss: 0.0249\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0825 - val_loss: 0.0233\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0933 - val_loss: 0.0159\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0916 - val_loss: 0.0147\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0589 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1021 - val_loss: 0.0140\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0931 - val_loss: 0.0133\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0967 - val_loss: 0.0137\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0768 - val_loss: 0.0138\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0792 - val_loss: 0.0138\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0547 - val_loss: 0.0141\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1160 - val_loss: 0.0127\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1231 - val_loss: 0.0148\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0852 - val_loss: 0.0126\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0799 - val_loss: 0.0121\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1034 - val_loss: 0.0193\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0734 - val_loss: 0.0174\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0735 - val_loss: 0.0152\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0675 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0812 - val_loss: 0.0127\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0725 - val_loss: 0.0118\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0793 - val_loss: 0.0125\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0591 - val_loss: 0.0123\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0833 - val_loss: 0.0157\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0535 - val_loss: 0.0182\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0835 - val_loss: 0.0148\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0703 - val_loss: 0.0226\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0817 - val_loss: 0.0247\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0778 - val_loss: 0.0113\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0746 - val_loss: 0.0170\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0652 - val_loss: 0.0347\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0588 - val_loss: 0.0249\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0750 - val_loss: 0.0175\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0798 - val_loss: 0.0195\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0728 - val_loss: 0.0143\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0644 - val_loss: 0.0144\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0782 - val_loss: 0.0265\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0854 - val_loss: 0.0097\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0812 - val_loss: 0.0094\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0712 - val_loss: 0.0098\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0582 - val_loss: 0.0109\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0496 - val_loss: 0.0103\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1305 - val_loss: 0.0112\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1049 - val_loss: 0.0120\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0748 - val_loss: 0.0104\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0853 - val_loss: 0.0114\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0760 - val_loss: 0.0109\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0597 - val_loss: 0.0103\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0629 - val_loss: 0.0132\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0600 - val_loss: 0.0108\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0650 - val_loss: 0.0113\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0664 - val_loss: 0.0163\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0967 - val_loss: 0.0209\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0531 - val_loss: 0.0138\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0754 - val_loss: 0.0137\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0666 - val_loss: 0.0107\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1036 - val_loss: 0.0103\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0482 - val_loss: 0.0187\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0698 - val_loss: 0.0128\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0681 - val_loss: 0.0103\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0483 - val_loss: 0.0356\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0669 - val_loss: 0.0528\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0736 - val_loss: 0.0305\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1025 - val_loss: 0.0108\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0737 - val_loss: 0.0216\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0747 - val_loss: 0.0229\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0587 - val_loss: 0.0189\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0604 - val_loss: 0.0106\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0474 - val_loss: 0.0105\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0571 - val_loss: 0.0154\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0670 - val_loss: 0.0180\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0744 - val_loss: 0.0199\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0667 - val_loss: 0.0094\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0753 - val_loss: 0.0113\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0640 - val_loss: 0.0196\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0523 - val_loss: 0.0208\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0474 - val_loss: 0.0129\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0632 - val_loss: 0.0118\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0528 - val_loss: 0.0081\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0619 - val_loss: 0.0080\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0682 - val_loss: 0.0298\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0719 - val_loss: 0.0223\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0560 - val_loss: 0.0079\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0534 - val_loss: 0.0139\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0437 - val_loss: 0.0266\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0787 - val_loss: 0.0155\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0397 - val_loss: 0.0097\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0408 - val_loss: 0.0095\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0613 - val_loss: 0.0149\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0519 - val_loss: 0.0123\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0784 - val_loss: 0.0083\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0452 - val_loss: 0.0102\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0778 - val_loss: 0.0155\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0664 - val_loss: 0.0134\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0639 - val_loss: 0.0078\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0403 - val_loss: 0.0149\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0496 - val_loss: 0.0235\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0591 - val_loss: 0.0096\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0650 - val_loss: 0.0092\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0668 - val_loss: 0.0082\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0437 - val_loss: 0.0095\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0513 - val_loss: 0.0107\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0794 - val_loss: 0.0189\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0473 - val_loss: 0.0695\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0334 - val_loss: 0.1171\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0377 - val_loss: 0.0946\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0531 - val_loss: 0.0466\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0766 - val_loss: 0.0130\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0467 - val_loss: 0.0099\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0449 - val_loss: 0.0238\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0592 - val_loss: 0.0176\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0450 - val_loss: 0.0094\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0893 - val_loss: 0.0091\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0674 - val_loss: 0.0086\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0536 - val_loss: 0.0334\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0398 - val_loss: 0.0734\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0453 - val_loss: 0.0854\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0411 - val_loss: 0.0747\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0802 - val_loss: 0.0417\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0452 - val_loss: 0.0329\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0402 - val_loss: 0.0550\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0750 - val_loss: 0.0333\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0371 - val_loss: 0.0225\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0409 - val_loss: 0.0186\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0417 - val_loss: 0.0127\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0586 - val_loss: 0.0078\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0396 - val_loss: 0.0079\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0897 - val_loss: 0.0103\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0491 - val_loss: 0.0149\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0398 - val_loss: 0.0188\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0644 - val_loss: 0.0203\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0466 - val_loss: 0.0285\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0400 - val_loss: 0.0330\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0540 - val_loss: 0.0196\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0420 - val_loss: 0.0167\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0448 - val_loss: 0.0098\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0443 - val_loss: 0.0083\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0433 - val_loss: 0.0086\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0658 - val_loss: 0.0155\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0457 - val_loss: 0.0185\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0587 - val_loss: 0.0113\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0331 - val_loss: 0.0081\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0455 - val_loss: 0.0106\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0899 - val_loss: 0.0211\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0341 - val_loss: 0.0207\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0633 - val_loss: 0.0129\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0607 - val_loss: 0.0088\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0374 - val_loss: 0.0105\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0490 - val_loss: 0.0084\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0375 - val_loss: 0.0113\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0343 - val_loss: 0.0127\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0567 - val_loss: 0.0101\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0430 - val_loss: 0.0091\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0382 - val_loss: 0.0114\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0438 - val_loss: 0.0135\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0482 - val_loss: 0.0147\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0324 - val_loss: 0.0110\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0345 - val_loss: 0.0087\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0384 - val_loss: 0.0121\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0397 - val_loss: 0.0144\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0342 - val_loss: 0.0118\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0423 - val_loss: 0.0105\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0438 - val_loss: 0.0091\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0409 - val_loss: 0.0079\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0557 - val_loss: 0.0133\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0356 - val_loss: 0.0123\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0401 - val_loss: 0.0196\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0491 - val_loss: 0.0178\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0368 - val_loss: 0.0086\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0353 - val_loss: 0.0084\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0510 - val_loss: 0.0111\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0509 - val_loss: 0.0088\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0458 - val_loss: 0.0102\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0350 - val_loss: 0.0120\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0451 - val_loss: 0.0118\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0376 - val_loss: 0.0080\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0359 - val_loss: 0.0085\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0326 - val_loss: 0.0079\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0404 - val_loss: 0.0081\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0387 - val_loss: 0.0106\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0343 - val_loss: 0.0228\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0400 - val_loss: 0.0257\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0311 - val_loss: 0.0122\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0339 - val_loss: 0.0088\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0357 - val_loss: 0.0082\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0469 - val_loss: 0.0081\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0416 - val_loss: 0.0078\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0601 - val_loss: 0.0091\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0378 - val_loss: 0.0125\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0329 - val_loss: 0.0083\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0278 - val_loss: 0.0085\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0358 - val_loss: 0.0080\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0390 - val_loss: 0.0108\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0326 - val_loss: 0.0161\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0384 - val_loss: 0.0098\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0324 - val_loss: 0.0079\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0434 - val_loss: 0.0081\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0436 - val_loss: 0.0084\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0509 - val_loss: 0.0094\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0273 - val_loss: 0.0089\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0463 - val_loss: 0.0119\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0278 - val_loss: 0.0191\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0355 - val_loss: 0.0155\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0350 - val_loss: 0.0104\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0112\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0354 - val_loss: 0.0190\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0608 - val_loss: 0.0112\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0373 - val_loss: 0.0119\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0452 - val_loss: 0.0229\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0680 - val_loss: 0.0572\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0492 - val_loss: 0.0761\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0526 - val_loss: 0.0564\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0502 - val_loss: 0.0109\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0207 - val_loss: 0.0172\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0349 - val_loss: 0.0536\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0478 - val_loss: 0.0416\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0302 - val_loss: 0.0175\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0371 - val_loss: 0.0082\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0369 - val_loss: 0.0146\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0354 - val_loss: 0.0293\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0477 - val_loss: 0.0175\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0275 - val_loss: 0.0091\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0482 - val_loss: 0.0146\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0304 - val_loss: 0.0215\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0307 - val_loss: 0.0103\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0350 - val_loss: 0.0094\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0341 - val_loss: 0.0148\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0291 - val_loss: 0.0152\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0309 - val_loss: 0.0129\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0287 - val_loss: 0.0086\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0413 - val_loss: 0.0083\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0377 - val_loss: 0.0126\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0495 - val_loss: 0.0175\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0328 - val_loss: 0.0168\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0377 - val_loss: 0.0107\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0270 - val_loss: 0.0085\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0347 - val_loss: 0.0090\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0411 - val_loss: 0.0098\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0300 - val_loss: 0.0103\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0238 - val_loss: 0.0117\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0554 - val_loss: 0.0096\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0335 - val_loss: 0.0081\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0283 - val_loss: 0.0097\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0332 - val_loss: 0.0170\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0452 - val_loss: 0.0273\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0243 - val_loss: 0.0249\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0421 - val_loss: 0.0268\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0407 - val_loss: 0.0219\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0315 - val_loss: 0.0105\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0327 - val_loss: 0.0077\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0403 - val_loss: 0.0081\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0397 - val_loss: 0.0109\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0348 - val_loss: 0.0159\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0439 - val_loss: 0.0117\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0287 - val_loss: 0.0090\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0419 - val_loss: 0.0103\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0408 - val_loss: 0.0104\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0397 - val_loss: 0.0100\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0441 - val_loss: 0.0084\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0346 - val_loss: 0.0103\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0313 - val_loss: 0.0116\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0368 - val_loss: 0.0082\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0400 - val_loss: 0.0087\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 0.0080\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0084\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0238 - val_loss: 0.0089\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0306 - val_loss: 0.0083\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0276 - val_loss: 0.0112\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0441 - val_loss: 0.0218\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0471 - val_loss: 0.0144\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0374 - val_loss: 0.0086\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0230 - val_loss: 0.0081\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0242 - val_loss: 0.0084\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0355 - val_loss: 0.0109\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0288 - val_loss: 0.0182\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0332 - val_loss: 0.0228\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0287 - val_loss: 0.0157\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0366 - val_loss: 0.0130\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0341 - val_loss: 0.0116\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0229 - val_loss: 0.0127\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0545 - val_loss: 0.0126\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0414 - val_loss: 0.0081\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0317 - val_loss: 0.0148\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0411 - val_loss: 0.0091\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0089\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0228 - val_loss: 0.0128\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0285 - val_loss: 0.0156\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0425 - val_loss: 0.0139\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0294 - val_loss: 0.0102\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0304 - val_loss: 0.0086\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0372 - val_loss: 0.0080\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0298 - val_loss: 0.0151\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0245 - val_loss: 0.0284\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0355 - val_loss: 0.0403\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0349 - val_loss: 0.0292\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0325 - val_loss: 0.0133\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0220 - val_loss: 0.0078\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0378 - val_loss: 0.0104\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0252 - val_loss: 0.0161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soc_model.compile(optimizer=Adam(learning_rate=0.00001), loss='mean_squared_error')  # Change loss if it's a classification problem\n"
      ],
      "metadata": {
        "id": "hmaSnqjq__p6"
      },
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = soc_model.fit(X_train, y_train, validation_split=0.2, epochs=600, batch_size=128, verbose=1)"
      ],
      "metadata": {
        "id": "KYle-88GNhwR",
        "outputId": "c35225b4-474f-441a-ca07-607e6ae74b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "5/5 [==============================] - 2s 70ms/step - loss: 0.0190 - val_loss: 0.0078\n",
            "Epoch 2/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0232 - val_loss: 0.0077\n",
            "Epoch 3/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0223 - val_loss: 0.0073\n",
            "Epoch 4/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0072\n",
            "Epoch 5/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0221 - val_loss: 0.0071\n",
            "Epoch 6/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0207 - val_loss: 0.0072\n",
            "Epoch 7/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0073\n",
            "Epoch 8/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0227 - val_loss: 0.0075\n",
            "Epoch 9/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0075\n",
            "Epoch 10/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0232 - val_loss: 0.0079\n",
            "Epoch 11/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0262 - val_loss: 0.0081\n",
            "Epoch 12/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0220 - val_loss: 0.0081\n",
            "Epoch 13/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0081\n",
            "Epoch 14/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0220 - val_loss: 0.0079\n",
            "Epoch 15/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0217 - val_loss: 0.0080\n",
            "Epoch 16/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 0.0078\n",
            "Epoch 17/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0275 - val_loss: 0.0080\n",
            "Epoch 18/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0206 - val_loss: 0.0090\n",
            "Epoch 19/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0224 - val_loss: 0.0096\n",
            "Epoch 20/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0298 - val_loss: 0.0098\n",
            "Epoch 21/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0162 - val_loss: 0.0102\n",
            "Epoch 22/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0257 - val_loss: 0.0106\n",
            "Epoch 23/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0242 - val_loss: 0.0106\n",
            "Epoch 24/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0221 - val_loss: 0.0104\n",
            "Epoch 25/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0099\n",
            "Epoch 26/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0226 - val_loss: 0.0096\n",
            "Epoch 27/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0164 - val_loss: 0.0094\n",
            "Epoch 28/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0220 - val_loss: 0.0090\n",
            "Epoch 29/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0086\n",
            "Epoch 30/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0204 - val_loss: 0.0083\n",
            "Epoch 31/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0246 - val_loss: 0.0080\n",
            "Epoch 32/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0197 - val_loss: 0.0076\n",
            "Epoch 33/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0074\n",
            "Epoch 34/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0073\n",
            "Epoch 35/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0274 - val_loss: 0.0072\n",
            "Epoch 36/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0292 - val_loss: 0.0074\n",
            "Epoch 37/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0075\n",
            "Epoch 38/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.0076\n",
            "Epoch 39/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0247 - val_loss: 0.0079\n",
            "Epoch 40/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0080\n",
            "Epoch 41/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0080\n",
            "Epoch 42/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0078\n",
            "Epoch 43/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0229 - val_loss: 0.0076\n",
            "Epoch 44/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0076\n",
            "Epoch 45/600\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0203 - val_loss: 0.0076\n",
            "Epoch 46/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0328 - val_loss: 0.0074\n",
            "Epoch 47/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0199 - val_loss: 0.0073\n",
            "Epoch 48/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0296 - val_loss: 0.0074\n",
            "Epoch 49/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0077\n",
            "Epoch 50/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0081\n",
            "Epoch 51/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0177 - val_loss: 0.0084\n",
            "Epoch 52/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0086\n",
            "Epoch 53/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0202 - val_loss: 0.0083\n",
            "Epoch 54/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0278 - val_loss: 0.0079\n",
            "Epoch 55/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0238 - val_loss: 0.0076\n",
            "Epoch 56/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0243 - val_loss: 0.0076\n",
            "Epoch 57/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0197 - val_loss: 0.0077\n",
            "Epoch 58/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0215 - val_loss: 0.0078\n",
            "Epoch 59/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0233 - val_loss: 0.0078\n",
            "Epoch 60/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0266 - val_loss: 0.0079\n",
            "Epoch 61/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0230 - val_loss: 0.0078\n",
            "Epoch 62/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0235 - val_loss: 0.0076\n",
            "Epoch 63/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0172 - val_loss: 0.0075\n",
            "Epoch 64/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0179 - val_loss: 0.0074\n",
            "Epoch 65/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.0074\n",
            "Epoch 66/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0074\n",
            "Epoch 67/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0273 - val_loss: 0.0074\n",
            "Epoch 68/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0254 - val_loss: 0.0074\n",
            "Epoch 69/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0075\n",
            "Epoch 70/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0219 - val_loss: 0.0076\n",
            "Epoch 71/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0076\n",
            "Epoch 72/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0218 - val_loss: 0.0077\n",
            "Epoch 73/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0077\n",
            "Epoch 74/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0233 - val_loss: 0.0077\n",
            "Epoch 75/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0077\n",
            "Epoch 76/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0076\n",
            "Epoch 77/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0074\n",
            "Epoch 78/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0073\n",
            "Epoch 79/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0073\n",
            "Epoch 80/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0073\n",
            "Epoch 81/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0074\n",
            "Epoch 82/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.0074\n",
            "Epoch 83/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0074\n",
            "Epoch 84/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0246 - val_loss: 0.0074\n",
            "Epoch 85/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0169 - val_loss: 0.0076\n",
            "Epoch 86/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0078\n",
            "Epoch 87/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0078\n",
            "Epoch 88/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0079\n",
            "Epoch 89/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0078\n",
            "Epoch 90/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0300 - val_loss: 0.0080\n",
            "Epoch 91/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0247 - val_loss: 0.0081\n",
            "Epoch 92/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0080\n",
            "Epoch 93/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0249 - val_loss: 0.0077\n",
            "Epoch 94/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0220 - val_loss: 0.0077\n",
            "Epoch 95/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0076\n",
            "Epoch 96/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0200 - val_loss: 0.0074\n",
            "Epoch 97/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0072\n",
            "Epoch 98/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0216 - val_loss: 0.0073\n",
            "Epoch 99/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0073\n",
            "Epoch 100/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0075\n",
            "Epoch 101/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0076\n",
            "Epoch 102/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0231 - val_loss: 0.0076\n",
            "Epoch 103/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0077\n",
            "Epoch 104/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0078\n",
            "Epoch 105/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0228 - val_loss: 0.0079\n",
            "Epoch 106/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0217 - val_loss: 0.0081\n",
            "Epoch 107/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0081\n",
            "Epoch 108/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0079\n",
            "Epoch 109/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0077\n",
            "Epoch 110/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0077\n",
            "Epoch 111/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0203 - val_loss: 0.0079\n",
            "Epoch 112/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0239 - val_loss: 0.0080\n",
            "Epoch 113/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0081\n",
            "Epoch 114/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0231 - val_loss: 0.0078\n",
            "Epoch 115/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0077\n",
            "Epoch 116/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0230 - val_loss: 0.0076\n",
            "Epoch 117/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0075\n",
            "Epoch 118/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0216 - val_loss: 0.0074\n",
            "Epoch 119/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0222 - val_loss: 0.0074\n",
            "Epoch 120/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0198 - val_loss: 0.0074\n",
            "Epoch 121/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0191 - val_loss: 0.0073\n",
            "Epoch 122/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0073\n",
            "Epoch 123/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0073\n",
            "Epoch 124/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0073\n",
            "Epoch 125/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0218 - val_loss: 0.0074\n",
            "Epoch 126/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0232 - val_loss: 0.0074\n",
            "Epoch 127/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0074\n",
            "Epoch 128/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0284 - val_loss: 0.0076\n",
            "Epoch 129/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0077\n",
            "Epoch 130/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0232 - val_loss: 0.0077\n",
            "Epoch 131/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0078\n",
            "Epoch 132/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0078\n",
            "Epoch 133/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0271 - val_loss: 0.0077\n",
            "Epoch 134/600\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0163 - val_loss: 0.0076\n",
            "Epoch 135/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0075\n",
            "Epoch 136/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0173 - val_loss: 0.0074\n",
            "Epoch 137/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0199 - val_loss: 0.0074\n",
            "Epoch 138/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0074\n",
            "Epoch 139/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0230 - val_loss: 0.0074\n",
            "Epoch 140/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0230 - val_loss: 0.0074\n",
            "Epoch 141/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0218 - val_loss: 0.0074\n",
            "Epoch 142/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0157 - val_loss: 0.0075\n",
            "Epoch 143/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0201 - val_loss: 0.0076\n",
            "Epoch 144/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0198 - val_loss: 0.0077\n",
            "Epoch 145/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0077\n",
            "Epoch 146/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0246 - val_loss: 0.0077\n",
            "Epoch 147/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0078\n",
            "Epoch 148/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0250 - val_loss: 0.0080\n",
            "Epoch 149/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0284 - val_loss: 0.0078\n",
            "Epoch 150/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0075\n",
            "Epoch 151/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0202 - val_loss: 0.0073\n",
            "Epoch 152/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0204 - val_loss: 0.0073\n",
            "Epoch 153/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.0073\n",
            "Epoch 154/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0073\n",
            "Epoch 155/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0199 - val_loss: 0.0075\n",
            "Epoch 156/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0077\n",
            "Epoch 157/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0211 - val_loss: 0.0077\n",
            "Epoch 158/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0078\n",
            "Epoch 159/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0078\n",
            "Epoch 160/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0221 - val_loss: 0.0077\n",
            "Epoch 161/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0075\n",
            "Epoch 162/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0249 - val_loss: 0.0075\n",
            "Epoch 163/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0075\n",
            "Epoch 164/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0132 - val_loss: 0.0075\n",
            "Epoch 165/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0183 - val_loss: 0.0074\n",
            "Epoch 166/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0233 - val_loss: 0.0075\n",
            "Epoch 167/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0205 - val_loss: 0.0075\n",
            "Epoch 168/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0075\n",
            "Epoch 169/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0229 - val_loss: 0.0076\n",
            "Epoch 170/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0077\n",
            "Epoch 171/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0145 - val_loss: 0.0079\n",
            "Epoch 172/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0202 - val_loss: 0.0079\n",
            "Epoch 173/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0209 - val_loss: 0.0077\n",
            "Epoch 174/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0077\n",
            "Epoch 175/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0244 - val_loss: 0.0075\n",
            "Epoch 176/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0192 - val_loss: 0.0074\n",
            "Epoch 177/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0074\n",
            "Epoch 178/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0195 - val_loss: 0.0074\n",
            "Epoch 179/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0074\n",
            "Epoch 180/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0192 - val_loss: 0.0074\n",
            "Epoch 181/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0264 - val_loss: 0.0074\n",
            "Epoch 182/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0074\n",
            "Epoch 183/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0074\n",
            "Epoch 184/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0074\n",
            "Epoch 185/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0073\n",
            "Epoch 186/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0073\n",
            "Epoch 187/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0214 - val_loss: 0.0073\n",
            "Epoch 188/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0073\n",
            "Epoch 189/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0210 - val_loss: 0.0073\n",
            "Epoch 190/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0073\n",
            "Epoch 191/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0202 - val_loss: 0.0073\n",
            "Epoch 192/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0191 - val_loss: 0.0073\n",
            "Epoch 193/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0074\n",
            "Epoch 194/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0073\n",
            "Epoch 195/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0073\n",
            "Epoch 196/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0074\n",
            "Epoch 197/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0074\n",
            "Epoch 198/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0074\n",
            "Epoch 199/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0214 - val_loss: 0.0076\n",
            "Epoch 200/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0078\n",
            "Epoch 201/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0202 - val_loss: 0.0079\n",
            "Epoch 202/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0079\n",
            "Epoch 203/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0079\n",
            "Epoch 204/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0079\n",
            "Epoch 205/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0078\n",
            "Epoch 206/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0079\n",
            "Epoch 207/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0080\n",
            "Epoch 208/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0196 - val_loss: 0.0079\n",
            "Epoch 209/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0210 - val_loss: 0.0076\n",
            "Epoch 210/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0192 - val_loss: 0.0074\n",
            "Epoch 211/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0074\n",
            "Epoch 212/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0225 - val_loss: 0.0073\n",
            "Epoch 213/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 214/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0074\n",
            "Epoch 215/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0073\n",
            "Epoch 216/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0073\n",
            "Epoch 217/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0073\n",
            "Epoch 218/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0215 - val_loss: 0.0073\n",
            "Epoch 219/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0211 - val_loss: 0.0073\n",
            "Epoch 220/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0073\n",
            "Epoch 221/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0233 - val_loss: 0.0073\n",
            "Epoch 222/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0074\n",
            "Epoch 223/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.0076\n",
            "Epoch 224/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0077\n",
            "Epoch 225/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0215 - val_loss: 0.0077\n",
            "Epoch 226/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0249 - val_loss: 0.0075\n",
            "Epoch 227/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0075\n",
            "Epoch 228/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0075\n",
            "Epoch 229/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0073\n",
            "Epoch 230/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0169 - val_loss: 0.0073\n",
            "Epoch 231/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0197 - val_loss: 0.0073\n",
            "Epoch 232/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0073\n",
            "Epoch 233/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0073\n",
            "Epoch 234/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0198 - val_loss: 0.0073\n",
            "Epoch 235/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0073\n",
            "Epoch 236/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0188 - val_loss: 0.0075\n",
            "Epoch 237/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0076\n",
            "Epoch 238/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0078\n",
            "Epoch 239/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0178 - val_loss: 0.0080\n",
            "Epoch 240/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0213 - val_loss: 0.0078\n",
            "Epoch 241/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0075\n",
            "Epoch 242/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0163 - val_loss: 0.0074\n",
            "Epoch 243/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.0075\n",
            "Epoch 244/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0074\n",
            "Epoch 245/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0200 - val_loss: 0.0072\n",
            "Epoch 246/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0073\n",
            "Epoch 247/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0303 - val_loss: 0.0073\n",
            "Epoch 248/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0180 - val_loss: 0.0073\n",
            "Epoch 249/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0075\n",
            "Epoch 250/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0077\n",
            "Epoch 251/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0077\n",
            "Epoch 252/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0075\n",
            "Epoch 253/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0144 - val_loss: 0.0073\n",
            "Epoch 254/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0073\n",
            "Epoch 255/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0072\n",
            "Epoch 256/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0225 - val_loss: 0.0072\n",
            "Epoch 257/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0072\n",
            "Epoch 258/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0234 - val_loss: 0.0073\n",
            "Epoch 259/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 0.0074\n",
            "Epoch 260/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0208 - val_loss: 0.0075\n",
            "Epoch 261/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0076\n",
            "Epoch 262/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0205 - val_loss: 0.0074\n",
            "Epoch 263/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0074\n",
            "Epoch 264/600\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0204 - val_loss: 0.0074\n",
            "Epoch 265/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0171 - val_loss: 0.0073\n",
            "Epoch 266/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0072\n",
            "Epoch 267/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0213 - val_loss: 0.0072\n",
            "Epoch 268/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0203 - val_loss: 0.0071\n",
            "Epoch 269/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0072\n",
            "Epoch 270/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0072\n",
            "Epoch 271/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0176 - val_loss: 0.0072\n",
            "Epoch 272/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0072\n",
            "Epoch 273/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0223 - val_loss: 0.0071\n",
            "Epoch 274/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0178 - val_loss: 0.0072\n",
            "Epoch 275/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0230 - val_loss: 0.0073\n",
            "Epoch 276/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0168 - val_loss: 0.0073\n",
            "Epoch 277/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0171 - val_loss: 0.0074\n",
            "Epoch 278/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0185 - val_loss: 0.0075\n",
            "Epoch 279/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0076\n",
            "Epoch 280/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0075\n",
            "Epoch 281/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0220 - val_loss: 0.0074\n",
            "Epoch 282/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0073\n",
            "Epoch 283/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0072\n",
            "Epoch 284/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0185 - val_loss: 0.0072\n",
            "Epoch 285/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0236 - val_loss: 0.0072\n",
            "Epoch 286/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0221 - val_loss: 0.0073\n",
            "Epoch 287/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0073\n",
            "Epoch 288/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0073\n",
            "Epoch 289/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0072\n",
            "Epoch 290/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0072\n",
            "Epoch 291/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0187 - val_loss: 0.0072\n",
            "Epoch 292/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0072\n",
            "Epoch 293/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0170 - val_loss: 0.0072\n",
            "Epoch 294/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0072\n",
            "Epoch 295/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0072\n",
            "Epoch 296/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0073\n",
            "Epoch 297/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0185 - val_loss: 0.0073\n",
            "Epoch 298/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0209 - val_loss: 0.0073\n",
            "Epoch 299/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.0074\n",
            "Epoch 300/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0074\n",
            "Epoch 301/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0073\n",
            "Epoch 302/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0073\n",
            "Epoch 303/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0073\n",
            "Epoch 304/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0073\n",
            "Epoch 305/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0073\n",
            "Epoch 306/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0073\n",
            "Epoch 307/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0205 - val_loss: 0.0073\n",
            "Epoch 308/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0073\n",
            "Epoch 309/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0072\n",
            "Epoch 310/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0142 - val_loss: 0.0072\n",
            "Epoch 311/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0139 - val_loss: 0.0073\n",
            "Epoch 312/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0073\n",
            "Epoch 313/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0245 - val_loss: 0.0076\n",
            "Epoch 314/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0076\n",
            "Epoch 315/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0182 - val_loss: 0.0074\n",
            "Epoch 316/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0219 - val_loss: 0.0073\n",
            "Epoch 317/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0073\n",
            "Epoch 318/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0217 - val_loss: 0.0074\n",
            "Epoch 319/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0169 - val_loss: 0.0074\n",
            "Epoch 320/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0074\n",
            "Epoch 321/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0074\n",
            "Epoch 322/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0183 - val_loss: 0.0074\n",
            "Epoch 323/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0193 - val_loss: 0.0074\n",
            "Epoch 324/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0073\n",
            "Epoch 325/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0073\n",
            "Epoch 326/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0210 - val_loss: 0.0073\n",
            "Epoch 327/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0073\n",
            "Epoch 328/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0203 - val_loss: 0.0073\n",
            "Epoch 329/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0219 - val_loss: 0.0074\n",
            "Epoch 330/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0074\n",
            "Epoch 331/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0073\n",
            "Epoch 332/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0073\n",
            "Epoch 333/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0072\n",
            "Epoch 334/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0071\n",
            "Epoch 335/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0070\n",
            "Epoch 336/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.0070\n",
            "Epoch 337/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0070\n",
            "Epoch 338/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0070\n",
            "Epoch 339/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0211 - val_loss: 0.0070\n",
            "Epoch 340/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.0071\n",
            "Epoch 341/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0072\n",
            "Epoch 342/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0073\n",
            "Epoch 343/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0073\n",
            "Epoch 344/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0133 - val_loss: 0.0073\n",
            "Epoch 345/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 346/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0073\n",
            "Epoch 347/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0073\n",
            "Epoch 348/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0073\n",
            "Epoch 349/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0153 - val_loss: 0.0072\n",
            "Epoch 350/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0072\n",
            "Epoch 351/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0204 - val_loss: 0.0073\n",
            "Epoch 352/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0222 - val_loss: 0.0074\n",
            "Epoch 353/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0075\n",
            "Epoch 354/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0129 - val_loss: 0.0077\n",
            "Epoch 355/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0249 - val_loss: 0.0077\n",
            "Epoch 356/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0224 - val_loss: 0.0078\n",
            "Epoch 357/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0079\n",
            "Epoch 358/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0197 - val_loss: 0.0084\n",
            "Epoch 359/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0085\n",
            "Epoch 360/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0081\n",
            "Epoch 361/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0079\n",
            "Epoch 362/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0197 - val_loss: 0.0077\n",
            "Epoch 363/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0076\n",
            "Epoch 364/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0151 - val_loss: 0.0075\n",
            "Epoch 365/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0146 - val_loss: 0.0075\n",
            "Epoch 366/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0180 - val_loss: 0.0075\n",
            "Epoch 367/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0076\n",
            "Epoch 368/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0164 - val_loss: 0.0076\n",
            "Epoch 369/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0148 - val_loss: 0.0075\n",
            "Epoch 370/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0073\n",
            "Epoch 371/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0161 - val_loss: 0.0071\n",
            "Epoch 372/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0070\n",
            "Epoch 373/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0183 - val_loss: 0.0071\n",
            "Epoch 374/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0072\n",
            "Epoch 375/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0073\n",
            "Epoch 376/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0073\n",
            "Epoch 377/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 0.0073\n",
            "Epoch 378/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0160 - val_loss: 0.0073\n",
            "Epoch 379/600\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0159 - val_loss: 0.0073\n",
            "Epoch 380/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0203 - val_loss: 0.0074\n",
            "Epoch 381/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.0077\n",
            "Epoch 382/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0079\n",
            "Epoch 383/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0078\n",
            "Epoch 384/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0174 - val_loss: 0.0080\n",
            "Epoch 385/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0082\n",
            "Epoch 386/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0193 - val_loss: 0.0083\n",
            "Epoch 387/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0083\n",
            "Epoch 388/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0203 - val_loss: 0.0081\n",
            "Epoch 389/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0193 - val_loss: 0.0081\n",
            "Epoch 390/600\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0213 - val_loss: 0.0084\n",
            "Epoch 391/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0167 - val_loss: 0.0090\n",
            "Epoch 392/600\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0239 - val_loss: 0.0087\n",
            "Epoch 393/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0082\n",
            "Epoch 394/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0079\n",
            "Epoch 395/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0225 - val_loss: 0.0076\n",
            "Epoch 396/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0173 - val_loss: 0.0073\n",
            "Epoch 397/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0071\n",
            "Epoch 398/600\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0140 - val_loss: 0.0072\n",
            "Epoch 399/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0214 - val_loss: 0.0074\n",
            "Epoch 400/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0173 - val_loss: 0.0076\n",
            "Epoch 401/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0140 - val_loss: 0.0076\n",
            "Epoch 402/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0077\n",
            "Epoch 403/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0076\n",
            "Epoch 404/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0074\n",
            "Epoch 405/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0074\n",
            "Epoch 406/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0074\n",
            "Epoch 407/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0075\n",
            "Epoch 408/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0242 - val_loss: 0.0075\n",
            "Epoch 409/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0076\n",
            "Epoch 410/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0158 - val_loss: 0.0076\n",
            "Epoch 411/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0077\n",
            "Epoch 412/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0174 - val_loss: 0.0078\n",
            "Epoch 413/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0220 - val_loss: 0.0078\n",
            "Epoch 414/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0076\n",
            "Epoch 415/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0076\n",
            "Epoch 416/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0075\n",
            "Epoch 417/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0075\n",
            "Epoch 418/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0075\n",
            "Epoch 419/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0188 - val_loss: 0.0073\n",
            "Epoch 420/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0073\n",
            "Epoch 421/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0172 - val_loss: 0.0073\n",
            "Epoch 422/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0073\n",
            "Epoch 423/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0073\n",
            "Epoch 424/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0073\n",
            "Epoch 425/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0072\n",
            "Epoch 426/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0201 - val_loss: 0.0072\n",
            "Epoch 427/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0071\n",
            "Epoch 428/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0223 - val_loss: 0.0071\n",
            "Epoch 429/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0134 - val_loss: 0.0072\n",
            "Epoch 430/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0073\n",
            "Epoch 431/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0074\n",
            "Epoch 432/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0200 - val_loss: 0.0075\n",
            "Epoch 433/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0076\n",
            "Epoch 434/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0075\n",
            "Epoch 435/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0075\n",
            "Epoch 436/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0074\n",
            "Epoch 437/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0257 - val_loss: 0.0072\n",
            "Epoch 438/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.0072\n",
            "Epoch 439/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0072\n",
            "Epoch 440/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0072\n",
            "Epoch 441/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0074\n",
            "Epoch 442/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0190 - val_loss: 0.0075\n",
            "Epoch 443/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0075\n",
            "Epoch 444/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0168 - val_loss: 0.0075\n",
            "Epoch 445/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0149 - val_loss: 0.0075\n",
            "Epoch 446/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0182 - val_loss: 0.0078\n",
            "Epoch 447/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 0.0081\n",
            "Epoch 448/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0080\n",
            "Epoch 449/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0078\n",
            "Epoch 450/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0076\n",
            "Epoch 451/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0075\n",
            "Epoch 452/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0168 - val_loss: 0.0074\n",
            "Epoch 453/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0076\n",
            "Epoch 454/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0077\n",
            "Epoch 455/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0080\n",
            "Epoch 456/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0079\n",
            "Epoch 457/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0199 - val_loss: 0.0081\n",
            "Epoch 458/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.0081\n",
            "Epoch 459/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0178 - val_loss: 0.0082\n",
            "Epoch 460/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0081\n",
            "Epoch 461/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0169 - val_loss: 0.0078\n",
            "Epoch 462/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0076\n",
            "Epoch 463/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0076\n",
            "Epoch 464/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0074\n",
            "Epoch 465/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0072\n",
            "Epoch 466/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0181 - val_loss: 0.0072\n",
            "Epoch 467/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0073\n",
            "Epoch 468/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0073\n",
            "Epoch 469/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0074\n",
            "Epoch 470/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0073\n",
            "Epoch 471/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0072\n",
            "Epoch 472/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0072\n",
            "Epoch 473/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0072\n",
            "Epoch 474/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0160 - val_loss: 0.0072\n",
            "Epoch 475/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0073\n",
            "Epoch 476/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0172 - val_loss: 0.0072\n",
            "Epoch 477/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0072\n",
            "Epoch 478/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0072\n",
            "Epoch 479/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0073\n",
            "Epoch 480/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 481/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0073\n",
            "Epoch 482/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0074\n",
            "Epoch 483/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0073\n",
            "Epoch 484/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0166 - val_loss: 0.0073\n",
            "Epoch 485/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0186 - val_loss: 0.0073\n",
            "Epoch 486/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0157 - val_loss: 0.0074\n",
            "Epoch 487/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0074\n",
            "Epoch 488/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0159 - val_loss: 0.0076\n",
            "Epoch 489/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0218 - val_loss: 0.0077\n",
            "Epoch 490/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0215 - val_loss: 0.0078\n",
            "Epoch 491/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0078\n",
            "Epoch 492/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0077\n",
            "Epoch 493/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0076\n",
            "Epoch 494/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0076\n",
            "Epoch 495/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.0076\n",
            "Epoch 496/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0075\n",
            "Epoch 497/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0196 - val_loss: 0.0075\n",
            "Epoch 498/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0143 - val_loss: 0.0076\n",
            "Epoch 499/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0239 - val_loss: 0.0078\n",
            "Epoch 500/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0080\n",
            "Epoch 501/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0079\n",
            "Epoch 502/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0076\n",
            "Epoch 503/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0076\n",
            "Epoch 504/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0073\n",
            "Epoch 505/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0072\n",
            "Epoch 506/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0072\n",
            "Epoch 507/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.0073\n",
            "Epoch 508/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0074\n",
            "Epoch 509/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0075\n",
            "Epoch 510/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0156 - val_loss: 0.0075\n",
            "Epoch 511/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0076\n",
            "Epoch 512/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0076\n",
            "Epoch 513/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.0079\n",
            "Epoch 514/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0079\n",
            "Epoch 515/600\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0152 - val_loss: 0.0077\n",
            "Epoch 516/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0076\n",
            "Epoch 517/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0182 - val_loss: 0.0075\n",
            "Epoch 518/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 0.0074\n",
            "Epoch 519/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0202 - val_loss: 0.0074\n",
            "Epoch 520/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0073\n",
            "Epoch 521/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0073\n",
            "Epoch 522/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0132 - val_loss: 0.0073\n",
            "Epoch 523/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0175 - val_loss: 0.0072\n",
            "Epoch 524/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0161 - val_loss: 0.0071\n",
            "Epoch 525/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0072\n",
            "Epoch 526/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0073\n",
            "Epoch 527/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 528/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0073\n",
            "Epoch 529/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 530/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0073\n",
            "Epoch 531/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0073\n",
            "Epoch 532/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0073\n",
            "Epoch 533/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0072\n",
            "Epoch 534/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0072\n",
            "Epoch 535/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0072\n",
            "Epoch 536/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0072\n",
            "Epoch 537/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0072\n",
            "Epoch 538/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0072\n",
            "Epoch 539/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0071\n",
            "Epoch 540/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0130 - val_loss: 0.0071\n",
            "Epoch 541/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0072\n",
            "Epoch 542/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0071\n",
            "Epoch 543/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0071\n",
            "Epoch 544/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0071\n",
            "Epoch 545/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0072\n",
            "Epoch 546/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0071\n",
            "Epoch 547/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0072\n",
            "Epoch 548/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0073\n",
            "Epoch 549/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0152 - val_loss: 0.0074\n",
            "Epoch 550/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0201 - val_loss: 0.0074\n",
            "Epoch 551/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0074\n",
            "Epoch 552/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0073\n",
            "Epoch 553/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0072\n",
            "Epoch 554/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0232 - val_loss: 0.0072\n",
            "Epoch 555/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0072\n",
            "Epoch 556/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0072\n",
            "Epoch 557/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0076\n",
            "Epoch 558/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0143 - val_loss: 0.0081\n",
            "Epoch 559/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0085\n",
            "Epoch 560/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0087\n",
            "Epoch 561/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0223 - val_loss: 0.0085\n",
            "Epoch 562/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0081\n",
            "Epoch 563/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0078\n",
            "Epoch 564/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0075\n",
            "Epoch 565/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0074\n",
            "Epoch 566/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0157 - val_loss: 0.0073\n",
            "Epoch 567/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0173 - val_loss: 0.0072\n",
            "Epoch 568/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0072\n",
            "Epoch 569/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0072\n",
            "Epoch 570/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0072\n",
            "Epoch 571/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0072\n",
            "Epoch 572/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0072\n",
            "Epoch 573/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0144 - val_loss: 0.0071\n",
            "Epoch 574/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 0.0072\n",
            "Epoch 575/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0073\n",
            "Epoch 576/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0192 - val_loss: 0.0072\n",
            "Epoch 577/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0165 - val_loss: 0.0071\n",
            "Epoch 578/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0071\n",
            "Epoch 579/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0133 - val_loss: 0.0071\n",
            "Epoch 580/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0159 - val_loss: 0.0071\n",
            "Epoch 581/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0158 - val_loss: 0.0071\n",
            "Epoch 582/600\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0165 - val_loss: 0.0071\n",
            "Epoch 583/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0071\n",
            "Epoch 584/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0071\n",
            "Epoch 585/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0072\n",
            "Epoch 586/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0073\n",
            "Epoch 587/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0171 - val_loss: 0.0074\n",
            "Epoch 588/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0074\n",
            "Epoch 589/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0074\n",
            "Epoch 590/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0073\n",
            "Epoch 591/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0073\n",
            "Epoch 592/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0072\n",
            "Epoch 593/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0072\n",
            "Epoch 594/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0071\n",
            "Epoch 595/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0070\n",
            "Epoch 596/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0070\n",
            "Epoch 597/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0226 - val_loss: 0.0070\n",
            "Epoch 598/600\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0136 - val_loss: 0.0071\n",
            "Epoch 599/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0071\n",
            "Epoch 600/600\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0179 - val_loss: 0.0071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = soc_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n"
      ],
      "metadata": {
        "id": "AOZ3FrLsNm5J",
        "outputId": "300faf36-4639-44e4-a904-312d52200048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0114\n",
            "Test Loss: 0.011410081759095192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = soc_model.predict(X_test)\n",
        "predictions = [pred[0] for pred in predictions]"
      ],
      "metadata": {
        "id": "cEG9JtUvNoLa",
        "outputId": "365b89ef-872e-4d86-fb9a-af42a31e2331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_reshaped = predictions.reshape(-1, 1)\n",
        "dummy_array = np.full((len(predictions), 28), fill_value=0.5)  # Assuming 0.5 is the median value after MinMax scaling\n",
        "target_column_index = -1  # Assuming the last column is the target variable\n",
        "dummy_array[:, target_column_index] = predictions\n",
        "\n",
        "target_column_index = -1  # Assuming the last column is the target variable\n",
        "dummy_array[:, target_column_index] = predictions\n",
        "\n",
        "inversed_dummy_array = scaler.inverse_transform(dummy_array)\n",
        "\n",
        "inversed_predictions = inversed_dummy_array[:, target_column_index]\n",
        "\n",
        "\n",
        "dummy_array[:, target_column_index] = y_test\n",
        "\n",
        "inversed_dummy_array = scaler.inverse_transform(dummy_array)\n",
        "\n",
        "\n",
        "inversed_truth = inversed_dummy_array[:, target_column_index]\n",
        "# inversed_predictions"
      ],
      "metadata": {
        "id": "HViXHddDQyoo"
      },
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJnp5qDFTTLE"
      },
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = r2_score(inversed_truth, inversed_predictions)\n",
        "print(f'R-squared: {r_squared}')\n"
      ],
      "metadata": {
        "id": "ZUzC-2oVSRyw",
        "outputId": "df0f1b94-1f18-42aa-e502-cf5d4eb200bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.3069800662481561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test set\n",
        "# predictions = model.predict(X_test).flatten()\n",
        "\n",
        "# Plot the predictions against the actual values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(inversed_truth, inversed_predictions)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.plot([inversed_truth.min(), inversed_truth.max()], [inversed_truth.min(), inversed_truth.max()], 'k--', lw=3)  # Diagonal line\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RqW2XPeNNyzD",
        "outputId": "4c01bbfc-9400-434a-dc29-1cf77d425e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}