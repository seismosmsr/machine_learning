{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/summarize-chatgpt_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a396a50-291c-438d-91da-7761e1335c98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a396a50-291c-438d-91da-7761e1335c98",
        "outputId": "8fade196-2358-45f7-ea4a-f2680e95f322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "# for google colab you have to install this 2 library before run the code\n",
        "!pip install pypdf2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e325a76-920c-46e8-8fcf-76416ed262b3",
      "metadata": {
        "tags": [],
        "id": "7e325a76-920c-46e8-8fcf-76416ed262b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import re\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import json\n",
        "import zipfile\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zip_specific_csv_files_in_directory(directory_path, output_zipfile, starting_string):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.startswith(starting_string) and filename.endswith('.csv'):\n",
        "                filepath = os.path.join(directory_path, filename)\n",
        "                if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                    zipf.write(filepath, os.path.basename(filepath))  # Only write the base filename\n",
        "\n",
        "    print(f\"CSV files in '{directory_path}' starting with '{starting_string}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n"
      ],
      "metadata": {
        "id": "wDKEauM9e75R"
      },
      "id": "wDKEauM9e75R",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zip_selected_files(directory_path, output_zipfile, file_list):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in file_list:\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                zipf.write(filepath, os.path.basename(filepath))\n",
        "\n",
        "    print(f\"Selected files from '{directory_path}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n",
        "# file_list = ['file1.txt', 'file2.csv', 'image.jpg']\n"
      ],
      "metadata": {
        "id": "idUoyakDhYQn"
      },
      "id": "idUoyakDhYQn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
      "metadata": {
        "tags": [],
        "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9619f4a2-5ed8-4b21-8ade-76743443b8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  6965  100  6965    0     0  31853      0 --:--:-- --:--:-- --:--:-- 31949\n"
          ]
        }
      ],
      "source": [
        "# Download pdf direcly\n",
        "!curl -o paper.pdf https://www.researchgate.net/profile/Alexey-Mikhaylov/publication/342372335_Global_climate_change_and_greenhouse_effect/links/5f576af2299bf13a31ab136c/Global-climate-change-and-greenhouse-effect.pdf #change the url with pdf which you wanna download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140",
      "metadata": {
        "tags": [],
        "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140"
      },
      "outputs": [],
      "source": [
        "# Set the string that will contain the summary\n",
        "pdf_summary_text = \"\"\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file_path = \"paper.pdf\"\n",
        "\n",
        "# Read the PDF file using PyPDF2\n",
        "pdf_file = open(pdf_file_path, 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7cba399a-3ebd-4c27-817f-44545d916a7e",
      "metadata": {
        "id": "7cba399a-3ebd-4c27-817f-44545d916a7e"
      },
      "outputs": [],
      "source": [
        "# openai.api_key = \"\" #change the api key with yours"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in files:\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "        print(f\"Successfully deleted {file_path}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error deleting {file_path}: {e}\")"
      ],
      "metadata": {
        "id": "F585vGbwf8M-",
        "outputId": "876c9431-4b21-4097-833a-8db97dafc2e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F585vGbwf8M-",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully deleted paper_1_0_summary.json\n",
            "Successfully deleted paper_17_0_summary.json\n",
            "Successfully deleted paper_11_0_summary.json\n",
            "Successfully deleted paper_7_0_summary.json\n",
            "Successfully deleted paper_14_0_summary.json\n",
            "Successfully deleted paper_0_0_summary.json\n",
            "Successfully deleted paper_4_0_summary.json\n",
            "Successfully deleted paper_9_0_summary.json\n",
            "Successfully deleted paper_10_0_summary.json\n",
            "Successfully deleted paper_15_0_summary.json\n",
            "Successfully deleted paper_8_0_summary.json\n",
            "Successfully deleted paper_18_0_summary.json\n",
            "Successfully deleted paper_2_0_summary.json\n",
            "Successfully deleted paper_13_0_summary.json\n",
            "Successfully deleted paper_16_0_summary.json\n",
            "Successfully deleted paper_12_0_summary.json\n",
            "Successfully deleted paper_19_0_summary.json\n",
            "Successfully deleted paper_6_0_summary.json\n",
            "Successfully deleted paper_3_0_summary.json\n",
            "Successfully deleted paper_20_0_summary.json\n",
            "Successfully deleted paper_5_0_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page_text = pdf_reader.pages[1].extract_text().lower()\n",
        "paragraphs = [line.strip() for line in page_text.split('\\n \\n') if line.strip()]\n",
        "paragraphs_text = [f\"Paragraph {i+1}:\\n{paragraph}\\n\" for i, paragraph in enumerate(paragraphs)]\n",
        "paragraphs_text"
      ],
      "metadata": {
        "id": "o-cDbe5JmoC4"
      },
      "id": "o-cDbe5JmoC4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
        "outputId": "1aa0905e-d3c6-43a8-e761-eebf17f1cf35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ],
      "source": [
        "pdf_summary_text = \"\"\n",
        "# Loop through all the pages in the PDF file\n",
        "# range(len(pdf_reader.pages))\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    # Extract the text from the page\n",
        "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
        "\n",
        "\n",
        "    paragraphs = [line.strip() for line in page_text.split('\\n \\n') if line.strip()]\n",
        "    paragraphs_text = [f\"Paragraph {i+1}:\\n{paragraph}\\n\" for i, paragraph in enumerate(paragraphs)]\n",
        "\n",
        "    for para_num, para_text in enumerate(paragraphs_text):\n",
        "    # while bad_read:\n",
        "      response = openai.ChatCompletion.create(\n",
        "                      model=\"gpt-3.5-turbo\",\n",
        "                      messages=[\n",
        "                          {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Specfically, you are helping research the impact of climate change on global food systems. We are doing a literature review. We want to know what crops and food systems are being impacted by specific climate change hazards. Only respond in the form of comma seperated values (csv). You always return a correctly formatted csv.\"},\n",
        "                          {\"role\": \"user\", \"content\": f\"Summarize the following text as a JSON document. Do not reply with anything except a JSON document. Please identify any specific climate change hazards, what cropping or food systems they effect, where globally the impact will be experienced, the specific quote from the paragraph (no more than 100 characters), if the impact is generally positive or negative (sentiment), and approximately what magnitude (e.g. high medium low). Do not do anything that could possibly break JSON formatting. Please make sure that text entries do not use commas internal to any text entries in the table. Please only return a JSON. The elements should only be: region, cropping_system, impact, sentiment, magnitude, quote, page_number (you are working on page {page_num}), paragraph_number (you are working on paragraph {para_num}. Here is the text:{para_text}. Do not return anything but the properly formatted JSON. It is of the utmost importance that the response you give is a properly formatted JSON. If the paragraph does not contain any text about climate change hazards, return an empty JSON (two empty curly braces) \"},\n",
        "                          ])\n",
        "\n",
        "      page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "      pdf_summary_text+=page_summary + \"\\n\"\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_summary.txt\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(pdf_summary_text)\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_{page_num}_{para_num}_summary.json\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(page_summary)\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()\n",
        "\n",
        "with open(pdf_summary_file, \"r\") as file:\n",
        "    print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# List of files\n",
        "files = [f for f in os.listdir('/content/') if f.endswith('.json')]\n",
        "\n",
        "# List to store dataframes\n",
        "dfs = []\n",
        "\n",
        "# List to store filenames of failed JSONs\n",
        "failed_files = []\n",
        "\n",
        "# Read each file and convert to dataframe\n",
        "for file in files:\n",
        "    try:\n",
        "        with open(os.path.join('/content/', file), 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "            # If the JSON data is a list of dictionaries\n",
        "            if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
        "                df = pd.DataFrame(data)\n",
        "                dfs.append(df)\n",
        "\n",
        "            # If the JSON data is a single dictionary\n",
        "            elif isinstance(data, dict):\n",
        "                df = pd.DataFrame([data])\n",
        "                dfs.append(df)\n",
        "\n",
        "            # Handle other structures as needed\n",
        "            else:\n",
        "                print(f\"Unhandled data structure in {file}. Skipping.\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Failed to decode JSON for {file}. Adding to failed list.\")\n",
        "        failed_files.append(file)\n",
        "\n",
        "# Combine all dataframes\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Write combined dataframe to CSV\n",
        "combined_df.to_csv('merged_output.csv', index=False)\n",
        "\n",
        "# If there were any failed files, save them to a CSV\n",
        "if failed_files:\n",
        "    failed_df = pd.DataFrame(failed_files, columns=[\"Failed Filenames\"])\n",
        "    failed_df.to_csv('failed_files.csv', index=False)"
      ],
      "metadata": {
        "id": "UmlG3ih4bn3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee6045d-15cf-401d-c5df-4ee11e9cf141"
      },
      "id": "UmlG3ih4bn3t",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to decode JSON for paper_8_0_summary.json. Adding to failed list.\n",
            "Failed to decode JSON for paper_13_0_summary.json. Adding to failed list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# files"
      ],
      "metadata": {
        "id": "7d4gLz73e2K1"
      },
      "id": "7d4gLz73e2K1",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'jsons.zip', files)\n"
      ],
      "metadata": {
        "id": "CMboMDIde5n9",
        "outputId": "83df5497-4294-4918-f5ad-923d055bbee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CMboMDIde5n9",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'jsons.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'results_3.zip', ['paper.pdf','failed_files.csv','merged_output.csv','jsons.zip'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbO1rx9hep8D",
        "outputId": "a60dbfe9-ccce-40eb-c3bc-0e6ca5bd9fad"
      },
      "id": "sbO1rx9hep8D",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'results_3.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def summarize_pdf(pdf_path):\n",
        "    # Your code here that summarizes the PDF and returns a dictionary\n",
        "    # with keys corresponding to the column headers and values\n",
        "    # corresponding to the summarized data.\n",
        "    # Example: return {\"Title\": \"My PDF Title\", \"Summary\": \"This is a summary...\"}\n",
        "    pass\n",
        "\n",
        "def append_data_to_sheet(data, sheet):\n",
        "    # Convert the dictionary to a list to append as a row\n",
        "    row = [data[col].iloc[0] for col in sheet.row_values(1)] # Use headers to order data\n",
        "    sheet.append_row(row)\n",
        "\n",
        "# Set up Google Sheets API\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name('/content/precise-duality-203214-f20314634651.txt', scope)\n",
        "client = gspread.authorize(creds)\n",
        "sheet = client.open_by_key(\"1iM2fqvMhSsf11uLoWTfAU7cpKhSM0NnLx6MB7bmG9fM\").sheet1\n"
      ],
      "metadata": {
        "id": "sVIWq6lINqnr"
      },
      "id": "sVIWq6lINqnr",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/merged_output.csv')"
      ],
      "metadata": {
        "id": "Pq2n_Ft3YLhT"
      },
      "id": "Pq2n_Ft3YLhT",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = [df[col] for col in sheet.row_values(1)]  # Use headers to order data"
      ],
      "metadata": {
        "id": "OEk6JdtGXzxC"
      },
      "id": "OEk6JdtGXzxC",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "1UmbQZmCYigd"
      },
      "id": "1UmbQZmCYigd",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "append_data_to_sheet(df, sheet)"
      ],
      "metadata": {
        "id": "r0ImwtWEX4Yl"
      },
      "id": "r0ImwtWEX4Yl",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worksheet =  client.open_by_key(\"1iM2fqvMhSsf11uLoWTfAU7cpKhSM0NnLx6MB7bmG9fM\").worksheet(\"Sheet1\")  # Replace \"Sheet1\" with the name of your sheet\n"
      ],
      "metadata": {
        "id": "bfc05K7OZzRQ"
      },
      "id": "bfc05K7OZzRQ",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_row = len(sheet.get_all_values())  # This gets the number of rows with data\n",
        "print(sheet.row_values(last_row))  # This will print the last row's data\n"
      ],
      "metadata": {
        "id": "Y0q9xwNSZ273",
        "outputId": "88ce3a26-0c76-4f86-ce60-72c9e1e3968f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Y0q9xwNSZ273",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '', '', '', '', '', '', '', 'global', '', '', '', '', '', '1', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "id": "o7i3sQqEaXp5",
        "outputId": "b2f51840-da67-4c30-aa8d-73442b4b7b65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "o7i3sQqEaXp5",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_append = [[i for i in df.iloc[j]] for j in range(df.shape[0])]\n",
        "sheet.append_rows(data_to_append)\n"
      ],
      "metadata": {
        "id": "5weUuRy8jylY",
        "outputId": "0c82aaef-d0fc-4631-d0d6-894f3a1e4c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5weUuRy8jylY",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1iM2fqvMhSsf11uLoWTfAU7cpKhSM0NnLx6MB7bmG9fM',\n",
              " 'tableRange': 'Sheet1!I162:P163',\n",
              " 'updates': {'spreadsheetId': '1iM2fqvMhSsf11uLoWTfAU7cpKhSM0NnLx6MB7bmG9fM',\n",
              "  'updatedRange': 'Sheet1!I164:P182',\n",
              "  'updatedRows': 19,\n",
              "  'updatedColumns': 8,\n",
              "  'updatedCells': 152}}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}