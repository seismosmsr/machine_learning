{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/summarize-chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a396a50-291c-438d-91da-7761e1335c98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a396a50-291c-438d-91da-7761e1335c98",
        "outputId": "4c74ba16-75f4-44f8-cecc-b0dfa0cb00e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "# for google colab you have to install this 2 library before run the code\n",
        "!pip install pypdf2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7e325a76-920c-46e8-8fcf-76416ed262b3",
      "metadata": {
        "tags": [],
        "id": "7e325a76-920c-46e8-8fcf-76416ed262b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import re\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_specific_csv_files_in_directory(directory_path, output_zipfile, starting_string):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.startswith(starting_string) and filename.endswith('.csv'):\n",
        "                filepath = os.path.join(directory_path, filename)\n",
        "                if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                    zipf.write(filepath, os.path.basename(filepath))  # Only write the base filename\n",
        "\n",
        "    print(f\"CSV files in '{directory_path}' starting with '{starting_string}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n"
      ],
      "metadata": {
        "id": "wDKEauM9e75R"
      },
      "id": "wDKEauM9e75R",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_selected_files(directory_path, output_zipfile, file_list):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in file_list:\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                zipf.write(filepath, os.path.basename(filepath))\n",
        "\n",
        "    print(f\"Selected files from '{directory_path}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n",
        "# file_list = ['file1.txt', 'file2.csv', 'image.jpg']\n"
      ],
      "metadata": {
        "id": "idUoyakDhYQn"
      },
      "id": "idUoyakDhYQn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
      "metadata": {
        "tags": [],
        "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5419bf-1c06-4f13-ad81-4b3e005a026d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  416k  100  416k    0     0   814k      0 --:--:-- --:--:-- --:--:--  815k\n"
          ]
        }
      ],
      "source": [
        "# Download pdf direcly\n",
        "!curl -o paper.pdf https://anr.vermont.gov/sites/anr/files/specialtopics/climate/documents/VTCCwhitepapers/VTCCAdaptAgriculture.pdf #change the url with pdf which you wanna download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140",
      "metadata": {
        "tags": [],
        "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140"
      },
      "outputs": [],
      "source": [
        "# Set the string that will contain the summary\n",
        "pdf_summary_text = \"\"\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file_path = \"paper.pdf\"\n",
        "\n",
        "# Read the PDF file using PyPDF2\n",
        "pdf_file = open(pdf_file_path, 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7cba399a-3ebd-4c27-817f-44545d916a7e",
      "metadata": {
        "id": "7cba399a-3ebd-4c27-817f-44545d916a7e"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"na\" #change the api key with yours"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for file_path in files:\n",
        "#     try:\n",
        "#         os.remove(file_path)\n",
        "#         print(f\"Successfully deleted {file_path}\")\n",
        "#     except OSError as e:\n",
        "#         print(f\"Error deleting {file_path}: {e}\")"
      ],
      "metadata": {
        "id": "F585vGbwf8M-"
      },
      "id": "F585vGbwf8M-",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
        "outputId": "7527e87a-fb74-47b3-eee2-e49316701b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ],
      "source": [
        "pdf_summary_text = \"\"\n",
        "# Loop through all the pages in the PDF file\n",
        "# range(len(pdf_reader.pages))\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    # Extract the text from the page\n",
        "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
        "\n",
        "\n",
        "    paragraphs = [line.strip() for line in page_text.split('\\n \\n') if line.strip()]\n",
        "    paragraphs_text = [f\"Paragraph {i+1}:\\n{paragraph}\\n\" for i, paragraph in enumerate(paragraphs)]\n",
        "\n",
        "    for para_num, para_text in enumerate(paragraphs_text):\n",
        "    # while bad_read:\n",
        "      response = openai.ChatCompletion.create(\n",
        "                      model=\"gpt-3.5-turbo\",\n",
        "                      messages=[\n",
        "                          {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Specfically, you are helping research the impact of climate change on global food systems. We are doing a literature review. We want to know what crops and food systems are being impacted by specific climate change hazards. Only respond in the form of comma seperated values (csv). You always return a correctly formatted csv.\"},\n",
        "                          {\"role\": \"user\", \"content\": f\"Summarize the following text as a JSON document. Do not reply with anything except a JSON document. Please identify any specific climate change hazards, what cropping or food systems they effect, where globally the impact will be experienced, the specific quote from the paragraph (no more than 100 characters), if the impact is generally positive or negative (sentiment), and approximately what magnitude (e.g. high medium low). Do not do anything that could possibly break JSON formatting. Please make sure that text entries do not use commas internal to any text entries in the table. Please only return a JSON. The elements should only be: region, cropping_system, impact, sentiment, magnitude, quote, page_number (you are working on page {page_num}), paragraph_number (you are working on paragraph {para_num}. Here is the text:{para_text}. Do not return anything but the properly formatted JSON. It is of the utmost importance that the response you give is a properly formatted JSON. If the paragraph does not contain any text about climate change hazards, return an empty JSON (two empty curly braces) \"},\n",
        "                          ])\n",
        "\n",
        "      page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "      pdf_summary_text+=page_summary + \"\\n\"\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_summary.txt\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(pdf_summary_text)\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_{page_num}_{para_num}_summary.json\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(page_summary)\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()\n",
        "\n",
        "with open(pdf_summary_file, \"r\") as file:\n",
        "    print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# List of files\n",
        "files = [f for f in os.listdir('/content/') if f.endswith('.json')]\n",
        "\n",
        "# List to store dataframes\n",
        "dfs = []\n",
        "\n",
        "# List to store filenames of failed JSONs\n",
        "failed_files = []\n",
        "\n",
        "# Read each file and convert to dataframe\n",
        "for file in files:\n",
        "    try:\n",
        "        with open(os.path.join('/content/', file), 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "            # If the JSON data is a list of dictionaries\n",
        "            if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
        "                df = pd.DataFrame(data)\n",
        "                dfs.append(df)\n",
        "\n",
        "            # If the JSON data is a single dictionary\n",
        "            elif isinstance(data, dict):\n",
        "                df = pd.DataFrame([data])\n",
        "                dfs.append(df)\n",
        "\n",
        "            # Handle other structures as needed\n",
        "            else:\n",
        "                print(f\"Unhandled data structure in {file}. Skipping.\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Failed to decode JSON for {file}. Adding to failed list.\")\n",
        "        failed_files.append(file)\n",
        "\n",
        "# Combine all dataframes\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Write combined dataframe to CSV\n",
        "combined_df.to_csv('merged_output.csv', index=False)\n",
        "\n",
        "# If there were any failed files, save them to a CSV\n",
        "if failed_files:\n",
        "    failed_df = pd.DataFrame(failed_files, columns=[\"Failed Filenames\"])\n",
        "    failed_df.to_csv('failed_files.csv', index=False)"
      ],
      "metadata": {
        "id": "UmlG3ih4bn3t"
      },
      "id": "UmlG3ih4bn3t",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files"
      ],
      "metadata": {
        "id": "7d4gLz73e2K1"
      },
      "id": "7d4gLz73e2K1",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'jsons.zip', files)\n"
      ],
      "metadata": {
        "id": "CMboMDIde5n9",
        "outputId": "cae53379-fb4d-4d2c-c08d-d4d6115e7e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CMboMDIde5n9",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'jsons.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'results_3.zip', ['paper.pdf','failed_files.csv','merged_output.csv','jsons.zip'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbO1rx9hep8D",
        "outputId": "95fab421-6084-4d27-d12b-183ae671501c"
      },
      "id": "sbO1rx9hep8D",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'results_3.zip'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}