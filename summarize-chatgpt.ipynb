{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/summarize-chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8a396a50-291c-438d-91da-7761e1335c98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a396a50-291c-438d-91da-7761e1335c98",
        "outputId": "80cf053c-0483-4b85-d308-357ac121a49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# for google colab you have to install this 2 library before run the code\n",
        "!pip install pypdf2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7e325a76-920c-46e8-8fcf-76416ed262b3",
      "metadata": {
        "tags": [],
        "id": "7e325a76-920c-46e8-8fcf-76416ed262b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import re\n",
        "import openai\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
      "metadata": {
        "tags": [],
        "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91"
      },
      "outputs": [],
      "source": [
        "# Download pdf direcly\n",
        "# !curl -o paper.pdf https://www.researchgate.net/profile/Jerry-Hatfield/publication/224147080_Climate_Impacts_on_Agriculture_Implications_for_Crop_Production/links/5464caa20cf267ed84f25c1a/Climate-Impacts-on-Agriculture-Implications-for-Crop-Production.pdf?origin=publicationDetail&_sg%5B0%5D=e1expVa__Rtw_KD82tLam-hYn_STxP9wHsv5YoKNi_OUJXMiYZnx5VxqZd1AQinKeazNscyKqsL8KCWfktR7Yg.XYHGPH8EnueYT8xATKpuFytnUpYuj68eKGCHzxCUDNA2CfiPongWbP4ITE6U9BjJyiDiENTpj2JAkp32lHuQ8g&_sg%5B1%5D=L8PLvwS9uHvi4iK4V__WRHlubrifW0EQY_PLF-Jg9T7RXVXsObMlV42GiE983vdrQFJWXXxPweE_KbcT5-8ze04xpO24eI0VIgPc56gNmH2E.XYHGPH8EnueYT8xATKpuFytnUpYuj68eKGCHzxCUDNA2CfiPongWbP4ITE6U9BjJyiDiENTpj2JAkp32lHuQ8g&_iepl=&_rtd=eyJjb250ZW50SW50ZW50IjoibWFpbkl0ZW0ifQ%3D%3D&_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCIsInBvc2l0aW9uIjoicGFnZUhlYWRlciJ9fQ #change the url with pdf which you wanna download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140",
      "metadata": {
        "tags": [],
        "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140"
      },
      "outputs": [],
      "source": [
        "# Set the string that will contain the summary\n",
        "pdf_summary_text = \"\"\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file_path = \"paper.pdf\"\n",
        "\n",
        "# Read the PDF file using PyPDF2\n",
        "pdf_file = open(pdf_file_path, 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7cba399a-3ebd-4c27-817f-44545d916a7e",
      "metadata": {
        "id": "7cba399a-3ebd-4c27-817f-44545d916a7e"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"na\" #change the api key with yours"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def merge_csvs_from_directory(directory_path, output_filename, failed_filename):\n",
        "    all_dataframes = []\n",
        "    failed_files = []\n",
        "    differing_structure_files = []\n",
        "\n",
        "    first_file = True\n",
        "    columns_of_first_file = None\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith('.csv'):\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                df = pd.read_csv(filepath)\n",
        "\n",
        "                # If it's the first file, save its columns\n",
        "                if first_file:\n",
        "                    columns_of_first_file = df.columns.tolist()\n",
        "                    first_file = False\n",
        "\n",
        "                # If columns don't match, skip this file\n",
        "                if df.columns.tolist() != columns_of_first_file:\n",
        "                    differing_structure_files.append(filename)\n",
        "                else:\n",
        "                    all_dataframes.append(df)\n",
        "            except Exception as e:\n",
        "                failed_files.append({'filename': filename, 'error': str(e)})\n",
        "                print(f\"Failed to read {filename} due to error: {e}\")\n",
        "\n",
        "    # Concatenate all successfully read dataframes with the same structure\n",
        "    if all_dataframes:\n",
        "        merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "    # Compile failures and differing structures into a single list\n",
        "    for file in differing_structure_files:\n",
        "        failed_files.append({'filename': file, 'error': 'Differing structure'})\n",
        "\n",
        "    # Write failed files to a separate CSV\n",
        "    if failed_files:\n",
        "        failed_df = pd.DataFrame(failed_files)\n",
        "        failed_df.to_csv(failed_filename, index=False)\n",
        "\n",
        "# Example usage\n",
        "# merge_csvs_from_directory('/path/to/csv/directory', 'merged_output.csv', 'failed_files.csv')\n"
      ],
      "metadata": {
        "id": "uPec-JeWIM8m"
      },
      "id": "uPec-JeWIM8m",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_specific_csv_files_in_directory(directory_path, output_zipfile, starting_string):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.startswith(starting_string) and filename.endswith('.csv'):\n",
        "                filepath = os.path.join(directory_path, filename)\n",
        "                if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                    zipf.write(filepath, os.path.basename(filepath))  # Only write the base filename\n",
        "\n",
        "    print(f\"CSV files in '{directory_path}' starting with '{starting_string}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n"
      ],
      "metadata": {
        "id": "wDKEauM9e75R"
      },
      "id": "wDKEauM9e75R",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_selected_files(directory_path, output_zipfile, file_list):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in file_list:\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                zipf.write(filepath, os.path.basename(filepath))\n",
        "\n",
        "    print(f\"Selected files from '{directory_path}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n",
        "# file_list = ['file1.txt', 'file2.csv', 'image.jpg']\n"
      ],
      "metadata": {
        "id": "idUoyakDhYQn"
      },
      "id": "idUoyakDhYQn",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def is_csv_empty(file_path):\n",
        "    return os.path.getsize(file_path) == 0\n",
        "\n",
        "def has_uneven_columns(df):\n",
        "    max_cols = len(df.columns)\n",
        "    for index, row in df.iterrows():\n",
        "        if len(row) != max_cols:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def fix_uneven_columns(df):\n",
        "    max_cols = len(df.columns)\n",
        "    mask = df.apply(len) != max_cols\n",
        "    rows_with_issues = df[mask].index.tolist()\n",
        "\n",
        "    # Drop rows with issues\n",
        "    df = df.drop(rows_with_issues)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "5DVlEnw9i5Pi"
      },
      "id": "5DVlEnw9i5Pi",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range(len(pdf_reader.pages))[14:]"
      ],
      "metadata": {
        "id": "hcSeSXgybKYS",
        "outputId": "0499c25a-8abf-4c5d-da47-f6dd9a719b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hcSeSXgybKYS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(14, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
        "outputId": "3a10c3bf-ad95-471c-9246-0da9b85ed0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No issues detected. File remains unchanged.\n",
            "No issues detected. File remains unchanged.\n",
            "No issues detected. File remains unchanged.\n",
            "Error reading file paper_17_summary.csv: Error tokenizing data. C error: Expected 7 fields in line 7, saw 8\n",
            "\n",
            "Attempt 1 failed.\n",
            "Error reading file paper_17_summary.csv: Error tokenizing data. C error: Expected 7 fields in line 27, saw 9\n",
            "\n",
            "Attempt 2 failed.\n",
            "Error reading file paper_17_summary.csv: Error tokenizing data. C error: Expected 7 fields in line 30, saw 8\n",
            "\n",
            "Attempt 3 failed.\n",
            "Error reading file paper_17_summary.csv: Error tokenizing data. C error: Expected 7 fields in line 25, saw 8\n",
            "\n",
            "Attempt 4 failed.\n",
            "No issues detected. File remains unchanged.\n",
            "No issues detected. File remains unchanged.\n",
            "No issues detected. File remains unchanged.\n",
            "No issues detected. File remains unchanged.\n",
            "region,cropping_system,impact,magnitude,quote,page_number,paragraph_number\n",
            "No Data,No Data,No Data,No Data,No Data,No Data,No Data\n"
          ]
        }
      ],
      "source": [
        "pdf_summary_text = \"\"\n",
        "# Loop through all the pages in the PDF file\n",
        "for page_num in range(len(pdf_reader.pages))[14:]:\n",
        "    # Extract the text from the page\n",
        "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
        "    # print(page_text)\n",
        "    bad_read = True\n",
        "    attempts = 0\n",
        "    while bad_read:\n",
        "      response = openai.ChatCompletion.create(\n",
        "                      model=\"gpt-3.5-turbo\",\n",
        "                      messages=[\n",
        "                          {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Specfically, you are helping research the impact of climate change on global food systems. We are doing a literature review. We want to know what crops and food systems are being impacted by specific climate change hazards. Only respond in the form of comma seperated values (csv). You always return a correctly formatted csv.\"},\n",
        "                          {\"role\": \"user\", \"content\": f\"Summarize the following text as a csv document. Do not reply with anything except a markdown document. Please identify any specific climate change hazards, what cropping or food systems they effect, where globally the impact will be experienced, the specific quote from the paper (no more than 100 characters), and approximately what magnitude (e.g. high medium low). I need a table of these results. In the quote, please replace any commas with hyphens. Commas will break the csv formatting. Do not do anything that could possibly break csv formatting. Please make sure that text entries do not use commas internal to any text entries in the table. Please only return a csv table of the hazard. The columns should only be: region, cropping_system, impact, magnitude, quote, page_number (you are working on page {page_num}), paragraph_number. Here is the text:{page_text}. Do not return anything but the properly formatted csv. If any row is missing data fill it with text that says 'No Data'. It is of the utmost importance that the response you give is a properly formatted csv.\"},\n",
        "                              ],\n",
        "                                  )\n",
        "      page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "      pdf_summary_text+=page_summary + \"\\n\"\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_summary.txt\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(pdf_summary_text)\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_{page_num}_summary.csv\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(page_summary)\n",
        "\n",
        "      # file_path = 'path_to_your_csv_file.csv'\n",
        "      attempts = attempts + 1\n",
        "      # Check if the CSV is empty\n",
        "      if is_csv_empty(pdf_summary_file):\n",
        "          print(f\"{pdf_summary_file} is empty.\")\n",
        "      else:\n",
        "          try:\n",
        "              df = pd.read_csv(pdf_summary_file)\n",
        "\n",
        "              # If the CSV has uneven columns, fix it\n",
        "              if has_uneven_columns(df):\n",
        "                  print(\"Fixing uneven columns...\")\n",
        "                  df = fix_uneven_columns(df)\n",
        "                  df.to_csv(pdf_summary_file, index=False)  # overwrite the original file with the fixed data\n",
        "                  bad_read = False\n",
        "\n",
        "              else:\n",
        "                  print(\"No issues detected. File remains unchanged.\")\n",
        "                  bad_read = False\n",
        "\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error reading file {pdf_summary_file}: {e}\")\n",
        "              print(f\"Attempt {attempts} failed.\")\n",
        "              bad_read = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()\n",
        "\n",
        "with open(pdf_summary_file, \"r\") as file:\n",
        "    print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_csvs_from_directory('/content/', 'merged_output.csv',failed_filename='failed_files.csv')"
      ],
      "metadata": {
        "id": "5DNsFfOZdXuF"
      },
      "id": "5DNsFfOZdXuF",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'results_3.zip', ['paper.pdf','merged_output.csv','failed_files.csv','csv_files.zip'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbO1rx9hep8D",
        "outputId": "c9266b72-b7d0-41cd-af6d-7fb48393e18f"
      },
      "id": "sbO1rx9hep8D",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'results_3.zip'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}