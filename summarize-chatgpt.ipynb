{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/summarize-chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a396a50-291c-438d-91da-7761e1335c98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a396a50-291c-438d-91da-7761e1335c98",
        "outputId": "5d336f44-224d-4a29-9bd1-a59aedd977ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "# for google colab you have to install this 2 library before run the code\n",
        "!pip install pypdf2\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "7e325a76-920c-46e8-8fcf-76416ed262b3",
      "metadata": {
        "tags": [],
        "id": "7e325a76-920c-46e8-8fcf-76416ed262b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import re\n",
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_csvs_from_directory(directory_path, output_filename, starting_string, failed_filename):\n",
        "    all_dataframes = []\n",
        "    failed_files = []\n",
        "    differing_structure_files = []\n",
        "\n",
        "    first_file = True\n",
        "    columns_of_first_file = None\n",
        "\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.startswith(starting_string) and filename.endswith('.csv'):\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                df = pd.read_csv(filepath)\n",
        "\n",
        "                # If it's the first file, save its columns\n",
        "                if first_file:\n",
        "                    columns_of_first_file = df.columns.tolist()\n",
        "                    first_file = False\n",
        "\n",
        "                # If columns don't match, skip this file\n",
        "                if df.columns.tolist() != columns_of_first_file:\n",
        "                    differing_structure_files.append(filename)\n",
        "                else:\n",
        "                    all_dataframes.append(df)\n",
        "            except Exception as e:\n",
        "                failed_files.append({'filename': filename, 'error': str(e)})\n",
        "                print(f\"Failed to read {filename} due to error: {e}\")\n",
        "\n",
        "    # Concatenate all successfully read dataframes with the same structure\n",
        "    if all_dataframes:\n",
        "        merged_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "    # Compile failures and differing structures into a single list\n",
        "    for file in differing_structure_files:\n",
        "        failed_files.append({'filename': file, 'error': 'Differing structure'})\n",
        "\n",
        "    # Write failed files to a separate CSV\n",
        "    if failed_files:\n",
        "        failed_df = pd.DataFrame(failed_files)\n",
        "        failed_df.to_csv(failed_filename, index=False)\n",
        "\n",
        "# Example usage\n",
        "# merge_csvs_from_directory('/path/to/csv/directory', 'merged_output.csv', 'failed_files.csv')\n"
      ],
      "metadata": {
        "id": "uPec-JeWIM8m"
      },
      "id": "uPec-JeWIM8m",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_specific_csv_files_in_directory(directory_path, output_zipfile, starting_string):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.startswith(starting_string) and filename.endswith('.csv'):\n",
        "                filepath = os.path.join(directory_path, filename)\n",
        "                if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                    zipf.write(filepath, os.path.basename(filepath))  # Only write the base filename\n",
        "\n",
        "    print(f\"CSV files in '{directory_path}' starting with '{starting_string}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n"
      ],
      "metadata": {
        "id": "wDKEauM9e75R"
      },
      "id": "wDKEauM9e75R",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_selected_files(directory_path, output_zipfile, file_list):\n",
        "    with zipfile.ZipFile(output_zipfile, 'w') as zipf:\n",
        "        for filename in file_list:\n",
        "            filepath = os.path.join(directory_path, filename)\n",
        "            if os.path.isfile(filepath):  # Ensure it's a file and not a directory\n",
        "                zipf.write(filepath, os.path.basename(filepath))\n",
        "\n",
        "    print(f\"Selected files from '{directory_path}' zipped to '{output_zipfile}'\")\n",
        "\n",
        "# Example usage\n",
        "# file_list = ['file1.txt', 'file2.csv', 'image.jpg']\n"
      ],
      "metadata": {
        "id": "idUoyakDhYQn"
      },
      "id": "idUoyakDhYQn",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def is_csv_empty(file_path):\n",
        "    return os.path.getsize(file_path) == 0\n",
        "\n",
        "def has_uneven_columns(df):\n",
        "    max_cols = len(df.columns)\n",
        "    for index, row in df.iterrows():\n",
        "        if len(row) != max_cols:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def fix_uneven_columns(df):\n",
        "    max_cols = len(df.columns)\n",
        "    mask = df.apply(len) != max_cols\n",
        "    rows_with_issues = df[mask].index.tolist()\n",
        "\n",
        "    # Drop rows with issues\n",
        "    df = df.drop(rows_with_issues)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "5DVlEnw9i5Pi"
      },
      "id": "5DVlEnw9i5Pi",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
      "metadata": {
        "tags": [],
        "id": "7bc8d77c-fdbf-4b0a-99bb-6e085389ad91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04710320-e799-4484-bf13-b8df299f2051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  416k  100  416k    0     0   317k      0  0:00:01  0:00:01 --:--:--  317k\n"
          ]
        }
      ],
      "source": [
        "# Download pdf direcly\n",
        "!curl -o paper.pdf https://anr.vermont.gov/sites/anr/files/specialtopics/climate/documents/VTCCwhitepapers/VTCCAdaptAgriculture.pdf #change the url with pdf which you wanna download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140",
      "metadata": {
        "tags": [],
        "id": "bba7f4a0-e74d-4b1f-8f5b-f763ec420140"
      },
      "outputs": [],
      "source": [
        "# Set the string that will contain the summary\n",
        "pdf_summary_text = \"\"\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file_path = \"paper.pdf\"\n",
        "\n",
        "# Read the PDF file using PyPDF2\n",
        "pdf_file = open(pdf_file_path, 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "7cba399a-3ebd-4c27-817f-44545d916a7e",
      "metadata": {
        "id": "7cba399a-3ebd-4c27-817f-44545d916a7e"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"na\" #change the api key with yours"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf_reader.pages[5].extract_text()\n",
        "range(len(pdf_reader.pages))[0:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTDksbN42pbI",
        "outputId": "715cf024-9ed3-4d42-b8ba-964e1e06a40b"
      },
      "id": "mTDksbN42pbI",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11617f-8ab5-4c27-b682-bb283b137804",
        "outputId": "899d3e05-331f-49ec-9dde-9f77a01407f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"region\": \"U.S. Northeast\",\n",
            "  \"cropping_system\": \"Agriculture\",\n",
            "  \"impact\": \"Climate Change\",\n",
            "  \"sentiment\": \"Negative\",\n",
            "  \"magnitude\": \"High\",\n",
            "  \"quote\": \"Climate change impacts on northeastern agriculture: an overview.\",\n",
            "  \"page_number\": \"5\",\n",
            "  \"paragraph_number\": \"5\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "pdf_summary_text = \"\"\n",
        "# Loop through all the pages in the PDF file\n",
        "# range(len(pdf_reader.pages))\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    # Extract the text from the page\n",
        "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
        "    # print(page_text)\n",
        "    bad_read = True\n",
        "    attempts = 0\n",
        "    while bad_read:\n",
        "      response = openai.ChatCompletion.create(\n",
        "                      model=\"gpt-3.5-turbo\",\n",
        "                      messages=[\n",
        "                          {\"role\": \"system\", \"content\": \"You are a helpful research assistant. Specfically, you are helping research the impact of climate change on global food systems. We are doing a literature review. We want to know what crops and food systems are being impacted by specific climate change hazards. Only respond in the form of comma seperated values (csv). You always return a correctly formatted csv.\"},\n",
        "                          {\"role\": \"user\", \"content\": f\"Summarize the following text as a JSON document. Do not reply with anything except a JSON document. Please identify any specific climate change hazards, what cropping or food systems they effect, where globally the impact will be experienced, the specific quote from the paper (no more than 100 characters), if the impact is generally positive or negative (sentiment), and approximately what magnitude (e.g. high medium low). Do not do anything that could possibly break JSON formatting. Please make sure that text entries do not use commas internal to any text entries in the table. Please only return a JSON. The elements should only be: region, cropping_system, impact, sentiment, magnitude, quote, page_number (you are working on page {page_num}), paragraph_number. Here is the text:{page_text}. Do not return anything but the properly formatted JSON. It is of the utmost importance that the response you give is a properly formatted JSON.\"},\n",
        "                          ])\n",
        "      page_summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "      pdf_summary_text+=page_summary + \"\\n\"\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_summary.txt\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(pdf_summary_text)\n",
        "\n",
        "      pdf_summary_file = pdf_file_path.replace(os.path.splitext(pdf_file_path)[1], f\"_{page_num}_summary.json\")\n",
        "\n",
        "      with open(pdf_summary_file, \"w+\") as file:\n",
        "          file.write(page_summary)\n",
        "\n",
        "      # file_path = 'path_to_your_csv_file.csv'\n",
        "      attempts = attempts + 1\n",
        "      # Check if the CSV is empty\n",
        "      # if is_csv_empty(pdf_summary_file):\n",
        "      #     print(f\"{pdf_summary_file} is empty.\")\n",
        "      # else:\n",
        "      #     try:\n",
        "      #         df = pd.read_csv(pdf_summary_file)\n",
        "\n",
        "      #         # If the CSV has uneven columns, fix it\n",
        "      #         if has_uneven_columns(df):\n",
        "      #             # print(\"Fixing uneven columns...\")\n",
        "      #             df = fix_uneven_columns(df)\n",
        "      #             df.to_csv(pdf_summary_file, index=False)  # overwrite the original file with the fixed data\n",
        "      #             bad_read = False\n",
        "\n",
        "      #         else:\n",
        "      #             print(\"No issues detected. File remains unchanged.\")\n",
        "      #             bad_read = False\n",
        "\n",
        "\n",
        "      #     except Exception as e:\n",
        "      #         print(f\"Error reading file {pdf_summary_file}: {e}\")\n",
        "      #         print(f\"Attempt {attempts} failed.\")\n",
        "      bad_read = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()\n",
        "\n",
        "with open(pdf_summary_file, \"r\") as file:\n",
        "    print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/paper_0_summary.csv')\n",
        "# df"
      ],
      "metadata": {
        "id": "4sKqOe5F6Q4F"
      },
      "id": "4sKqOe5F6Q4F",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "# Loop through all JSON files in the directory.\n",
        "for filename in os.listdir('/content/'):\n",
        "    if filename.endswith('.json'):\n",
        "        json_file = os.path.join('/content/', filename)\n",
        "\n",
        "        with open(json_file, 'r') as file:\n",
        "            print(file)\n",
        "            data = json.load(file)\n",
        "\n",
        "            # If your JSON data is a list of objects, you may need to flatten it as mentioned in the previous response.\n",
        "            # For this example, we assume each JSON file contains a list of objects.\n",
        "            all_data.extend(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IJzMFUP6uqW",
        "outputId": "077faf63-c663-43f3-d9c3-57e9a7953052"
      },
      "id": "_IJzMFUP6uqW",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/paper_0_summary.json' mode='r' encoding='UTF-8'>\n",
            "<_io.TextIOWrapper name='/content/paper_1_summary.json' mode='r' encoding='UTF-8'>\n",
            "<_io.TextIOWrapper name='/content/paper_4_summary.json' mode='r' encoding='UTF-8'>\n",
            "<_io.TextIOWrapper name='/content/paper_5_summary.json' mode='r' encoding='UTF-8'>\n",
            "<_io.TextIOWrapper name='/content/paper_3_summary.json' mode='r' encoding='UTF-8'>\n",
            "<_io.TextIOWrapper name='/content/paper_2_summary.json' mode='r' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXP1Ez-EbeVk",
        "outputId": "6fce2d8d-b4e2-47c0-e47c-278b2c1ce064"
      },
      "id": "UXP1Ez-EbeVk",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['region',\n",
              " 'cropping_system',\n",
              " 'impact',\n",
              " 'sentiment',\n",
              " 'magnitude',\n",
              " 'quote',\n",
              " 'page_number',\n",
              " 'paragraph_number',\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Warm-weather crops',\n",
              "  'impact': 'Increase in productivity',\n",
              "  'sentiment': 'Positive',\n",
              "  'magnitude': 'Moderate',\n",
              "  'quote': 'increase the productivity of warm-weather crops',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 2},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Cold-weather crops',\n",
              "  'impact': 'Decrease in productivity',\n",
              "  'sentiment': 'Negative',\n",
              "  'magnitude': 'Moderate',\n",
              "  'quote': 'cold-weather crops will be among the most vulnerable',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 4},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Grain crops, warm-weather crops',\n",
              "  'impact': 'Reduced productivity',\n",
              "  'sentiment': 'Negative',\n",
              "  'magnitude': 'Low',\n",
              "  'quote': 'grain crops such as field corn, wheat, and oats tend to experience lower yields when summer temperatures rise',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 4},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Fruits (apples, cranberries, blueberries)',\n",
              "  'impact': 'Potentially reduced yields',\n",
              "  'sentiment': 'Negative',\n",
              "  'magnitude': 'Low',\n",
              "  'quote': 'many fruits, including apples, cranberries and blueberries, require approximately 1,000 hours below 45°F each winter to produce profitable yields in the summer and fall',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 5},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Maple sugaring',\n",
              "  'impact': 'Uncertain impact',\n",
              "  'sentiment': 'N/A',\n",
              "  'magnitude': 'N/A',\n",
              "  'quote': 'the impact of climate change on maple syrup production is not certain',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 8},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Dairy industry',\n",
              "  'impact': 'Decrease in productivity',\n",
              "  'sentiment': 'Negative',\n",
              "  'magnitude': 'High',\n",
              "  'quote': 'if temperatures continue to rise at the current observed rate, it may cause a significant decrease in the productivity of the Vermont dairy industry',\n",
              "  'page_number': 1,\n",
              "  'paragraph_number': 10},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': '',\n",
              "  'impact': 'flooding and nutrient pollution',\n",
              "  'sentiment': 'negative',\n",
              "  'magnitude': '',\n",
              "  'quote': 're-establishment of river and floodplain connection',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 1},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'late summer and fall crops',\n",
              "  'impact': 'water supply',\n",
              "  'sentiment': 'negative',\n",
              "  'magnitude': 'medium',\n",
              "  'quote': 'irrigation efficiency may become essential',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 2},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Vermont farmers',\n",
              "  'impact': 'crop portfolio',\n",
              "  'sentiment': 'positive',\n",
              "  'magnitude': '',\n",
              "  'quote': 'potential opportunities for Vermont farmers',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 2},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'crops',\n",
              "  'impact': 'adaptability to climate change',\n",
              "  'sentiment': 'positive',\n",
              "  'magnitude': 'low',\n",
              "  'quote': 'determine the best crop portfolio',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 3},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'crops',\n",
              "  'impact': 'adaptability to higher temperatures, flooding, and drought',\n",
              "  'sentiment': 'positive',\n",
              "  'magnitude': 'low',\n",
              "  'quote': 'identify crops that can grow more successfully',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 3},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': '',\n",
              "  'impact': 'climate and growing seasons',\n",
              "  'sentiment': 'positive',\n",
              "  'magnitude': 'medium',\n",
              "  'quote': 'grow more successfully for the next 10 or 20 years',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 3},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': '',\n",
              "  'impact': 'climate change impact',\n",
              "  'sentiment': 'negative',\n",
              "  'magnitude': '',\n",
              "  'quote': 'farmers to identify adaptation strategies',\n",
              "  'page_number': 4,\n",
              "  'paragraph_number': 4},\n",
              " 'region',\n",
              " 'cropping_system',\n",
              " 'impact',\n",
              " 'sentiment',\n",
              " 'magnitude',\n",
              " 'quote',\n",
              " 'page_number',\n",
              " 'paragraph_number',\n",
              " 'region',\n",
              " 'cropping_system',\n",
              " 'impact',\n",
              " 'sentiment',\n",
              " 'magnitude',\n",
              " 'quote',\n",
              " 'page_number',\n",
              " 'paragraph_number',\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Agricultural lands',\n",
              "  'impact': 'Reduced atmospheric carbon storage potential',\n",
              "  'sentiment': 'Negative',\n",
              "  'magnitude': 'Medium',\n",
              "  'quote': 'farming practices will help determine how much co₂ can be sequestered',\n",
              "  'page_number': '2',\n",
              "  'paragraph_number': '1'},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Agricultural processes',\n",
              "  'impact': 'Increased landfill capacities',\n",
              "  'sentiment': 'Positive',\n",
              "  'magnitude': 'High',\n",
              "  'quote': 'the state could significantly increase landfill capacities by increasing education and incentives to reduce the amount of organic waste',\n",
              "  'page_number': '2',\n",
              "  'paragraph_number': '2'},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Producing farms',\n",
              "  'impact': 'Decreased need for fertilizers and pesticides',\n",
              "  'sentiment': 'Positive',\n",
              "  'magnitude': 'Medium',\n",
              "  'quote': 'improving composting incentives and re-using organic matter as fertilizer also decrease the need for fertilizers and pesticides on producing farms',\n",
              "  'page_number': '2',\n",
              "  'paragraph_number': '2'},\n",
              " {'region': 'Vermont',\n",
              "  'cropping_system': 'Landfills and dairy farms',\n",
              "  'impact': 'Reduction in GHG emissions',\n",
              "  'sentiment': 'Positive',\n",
              "  'magnitude': 'Medium',\n",
              "  'quote': 'supporting and expanding these programs will reduce vermont’s dependence on fossil fuels while reducing the state’s ghg emissions and supporting local farms',\n",
              "  'page_number': '2',\n",
              "  'paragraph_number': '2'}]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of files\n",
        "files = [f for f in os.listdir('/content/') if f.endswith('.json')]\n",
        "\n",
        "# List to store dataframes\n",
        "dfs = []\n",
        "\n",
        "# Read each file and convert to dataframe\n",
        "for file in files:\n",
        "    with open(file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "        # If the JSON data is a list of dictionaries\n",
        "        if isinstance(data, list) and all(isinstance(item, dict) for item in data):\n",
        "            df = pd.DataFrame(data)\n",
        "            dfs.append(df)\n",
        "\n",
        "        # If the JSON data is a single dictionary\n",
        "        elif isinstance(data, dict):\n",
        "            df = pd.DataFrame([data])\n",
        "            dfs.append(df)\n",
        "\n",
        "        # Handle other structures as needed\n",
        "        else:\n",
        "            print(f\"Unhandled data structure in {file}. Skipping.\")\n",
        "\n",
        "# Combine all dataframes\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Write combined dataframe to CSV\n",
        "combined_df.to_csv('merged_output.csv', index=False)\n"
      ],
      "metadata": {
        "id": "UmlG3ih4bn3t"
      },
      "id": "UmlG3ih4bn3t",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_csvs_from_directory('/content/', 'merged_output.csv','paper_',failed_filename='failed_files.csv')"
      ],
      "metadata": {
        "id": "5DNsFfOZdXuF"
      },
      "id": "5DNsFfOZdXuF",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_selected_files('/content/', 'results_3.zip', ['paper.pdf','merged_output.csv','failed_files.csv','csv_files.zip'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbO1rx9hep8D",
        "outputId": "e6183ae8-a3cb-42b2-c402-91504923381d"
      },
      "id": "sbO1rx9hep8D",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected files from '/content/' zipped to 'results_3.zip'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}