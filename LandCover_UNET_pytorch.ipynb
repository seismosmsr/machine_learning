{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/seismosmsr/machine_learning/blob/main/LandCover_UNET.ipynb",
      "authorship_tag": "ABX9TyMZ1xKLxXlSaHv2tkA+sb8v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/LandCover_UNET_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_OzYtqdUkAzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393c8045-c901-4d55-daa5-cde65c24eac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio scikit-image tensorflow keras gdown\n"
      ],
      "metadata": {
        "id": "LR60G0YWkCUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d7b3f3-7118-4f41-bd33-33a66999d969"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2022.12.7)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.3)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.22.4)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import rasterio\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "from keras.utils import to_categorical\n",
        "from skimage.util import random_noise"
      ],
      "metadata": {
        "id": "ZaTY93f9kDxy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the training dataset\n",
        "url = 'https://drive.google.com/uc?id=1f4eGmykyiczmNz2VPeNNmQ7aC7q8N_hD'\n",
        "output = '/content/california_land_use.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "cwd = os.getcwd()\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cwd+'/sample_data')\n"
      ],
      "metadata": {
        "id": "UvOfZH5skF8s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the inference dataset\n",
        "#https://drive.google.com/file/d/1mn00JDt51KlhyiVTfPJjRk7Ymzd_zB7n/view?usp=drive_link\n",
        "url = 'https://drive.google.com/uc?id=1mn00JDt51KlhyiVTfPJjRk7Ymzd_zB7n'\n",
        "output = '/content/california_land_use.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Extract the dataset\n",
        "cwd = os.getcwd()\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cwd+'/sample_data/inference_data/')"
      ],
      "metadata": {
        "id": "AdET8qGY1F_1",
        "outputId": "f3854c6f-4975-4f51-f221-d2e229e99af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mn00JDt51KlhyiVTfPJjRk7Ymzd_zB7n\n",
            "To: /content/california_land_use.zip\n",
            "100%|██████████| 331M/331M [00:05<00:00, 58.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, rgb_dir, labels_dir, transform=None):\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transform = transform\n",
        "        self.filenames = os.listdir(rgb_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with rasterio.open(os.path.join(self.rgb_dir, self.filenames[idx])) as src:\n",
        "            rgb_image = src.read().transpose((1, 2, 0))\n",
        "        with rasterio.open(os.path.join(self.labels_dir, self.filenames[idx])) as src:\n",
        "            label_image = src.read(1) - 1  # adjust labels to be 0-indexed\n",
        "        if self.transform:\n",
        "            rgb_image = self.transform(rgb_image)\n",
        "            label_image = torch.from_numpy(label_image).long()\n",
        "        return rgb_image, label_image\n",
        "\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_dataset = CustomDataset('/content/sample_data/training/rgbNIR', '/content/sample_data/training/labels', transform=transform)\n",
        "val_dataset = CustomDataset('/content/sample_data/validation/rgbNIR', '/content/sample_data/validation/labels', transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2,drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=2,drop_last=True)\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model\n",
        "model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
        "model.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.classifier[4] = nn.Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
        "\n",
        "# Transfer model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Transfer inputs and labels to GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)['out']\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # print every 10 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_val_loss = 0.0\n",
        "        for i, data in enumerate(val_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)['out']\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            running_val_loss += val_loss.item()\n",
        "        print('[%d] validation loss: %.3f' % (epoch + 1, running_val_loss / len(val_loader)))\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_u2zK8Zr56v",
        "outputId": "3eb77d41-9ffe-4159-f287-75dceeafe211"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    10] loss: 2.208\n",
            "[1,    20] loss: 1.753\n",
            "[1,    30] loss: 1.375\n",
            "[1,    40] loss: 1.093\n",
            "[1,    50] loss: 1.165\n",
            "[1,    60] loss: 1.042\n",
            "[1,    70] loss: 0.957\n",
            "[1,    80] loss: 0.985\n",
            "[1,    90] loss: 0.950\n",
            "[1,   100] loss: 0.883\n",
            "[1,   110] loss: 0.847\n",
            "[1,   120] loss: 0.819\n",
            "[1,   130] loss: 0.858\n",
            "[1,   140] loss: 0.844\n",
            "[1,   150] loss: 0.829\n",
            "[1,   160] loss: 0.732\n",
            "[1,   170] loss: 0.797\n",
            "[1,   180] loss: 0.729\n",
            "[1,   190] loss: 0.767\n",
            "[1,   200] loss: 0.744\n",
            "[1,   210] loss: 0.705\n",
            "[1,   220] loss: 0.673\n",
            "[1,   230] loss: 0.798\n",
            "[1,   240] loss: 0.720\n",
            "[1,   250] loss: 0.729\n",
            "[1,   260] loss: 0.756\n",
            "[1,   270] loss: 0.730\n",
            "[1,   280] loss: 0.634\n",
            "[1,   290] loss: 0.699\n",
            "[1,   300] loss: 0.653\n",
            "[1,   310] loss: 0.642\n",
            "[1,   320] loss: 0.692\n",
            "[1,   330] loss: 0.583\n",
            "[1,   340] loss: 0.660\n",
            "[1] validation loss: 0.901\n",
            "[2,    10] loss: 0.608\n",
            "[2,    20] loss: 0.657\n",
            "[2,    30] loss: 0.573\n",
            "[2,    40] loss: 0.563\n",
            "[2,    50] loss: 0.608\n",
            "[2,    60] loss: 0.661\n",
            "[2,    70] loss: 0.524\n",
            "[2,    80] loss: 0.586\n",
            "[2,    90] loss: 0.575\n",
            "[2,   100] loss: 0.595\n",
            "[2,   110] loss: 0.583\n",
            "[2,   120] loss: 0.546\n",
            "[2,   130] loss: 0.501\n",
            "[2,   140] loss: 0.601\n",
            "[2,   150] loss: 0.527\n",
            "[2,   160] loss: 0.507\n",
            "[2,   170] loss: 0.505\n",
            "[2,   180] loss: 0.448\n",
            "[2,   190] loss: 0.549\n",
            "[2,   200] loss: 0.530\n",
            "[2,   210] loss: 0.451\n",
            "[2,   220] loss: 0.458\n",
            "[2,   230] loss: 0.483\n",
            "[2,   240] loss: 0.499\n",
            "[2,   250] loss: 0.553\n",
            "[2,   260] loss: 0.488\n",
            "[2,   270] loss: 0.439\n",
            "[2,   280] loss: 0.440\n",
            "[2,   290] loss: 0.548\n",
            "[2,   300] loss: 0.509\n",
            "[2,   310] loss: 0.504\n",
            "[2,   320] loss: 0.469\n",
            "[2,   330] loss: 0.452\n",
            "[2,   340] loss: 0.444\n",
            "[2] validation loss: 0.833\n",
            "[3,    10] loss: 0.414\n",
            "[3,    20] loss: 0.451\n",
            "[3,    30] loss: 0.476\n",
            "[3,    40] loss: 0.488\n",
            "[3,    50] loss: 0.429\n",
            "[3,    60] loss: 0.445\n",
            "[3,    70] loss: 0.404\n",
            "[3,    80] loss: 0.507\n",
            "[3,    90] loss: 0.447\n",
            "[3,   100] loss: 0.408\n",
            "[3,   110] loss: 0.449\n",
            "[3,   120] loss: 0.405\n",
            "[3,   130] loss: 0.419\n",
            "[3,   140] loss: 0.375\n",
            "[3,   150] loss: 0.400\n",
            "[3,   160] loss: 0.384\n",
            "[3,   170] loss: 0.394\n",
            "[3,   180] loss: 0.378\n",
            "[3,   190] loss: 0.360\n",
            "[3,   200] loss: 0.362\n",
            "[3,   210] loss: 0.368\n",
            "[3,   220] loss: 0.354\n",
            "[3,   230] loss: 0.393\n",
            "[3,   240] loss: 0.378\n",
            "[3,   250] loss: 0.399\n",
            "[3,   260] loss: 0.342\n",
            "[3,   270] loss: 0.405\n",
            "[3,   280] loss: 0.374\n",
            "[3,   290] loss: 0.342\n",
            "[3,   300] loss: 0.341\n",
            "[3,   310] loss: 0.363\n",
            "[3,   320] loss: 0.421\n",
            "[3,   330] loss: 0.372\n",
            "[3,   340] loss: 0.456\n",
            "[3] validation loss: 0.838\n",
            "[4,    10] loss: 0.324\n",
            "[4,    20] loss: 0.342\n",
            "[4,    30] loss: 0.391\n",
            "[4,    40] loss: 0.391\n",
            "[4,    50] loss: 0.321\n",
            "[4,    60] loss: 0.313\n",
            "[4,    70] loss: 0.395\n",
            "[4,    80] loss: 0.275\n",
            "[4,    90] loss: 0.298\n",
            "[4,   100] loss: 0.336\n",
            "[4,   110] loss: 0.341\n",
            "[4,   120] loss: 0.379\n",
            "[4,   130] loss: 0.327\n",
            "[4,   140] loss: 0.366\n",
            "[4,   150] loss: 0.321\n",
            "[4,   160] loss: 0.334\n",
            "[4,   170] loss: 0.325\n",
            "[4,   180] loss: 0.333\n",
            "[4,   190] loss: 0.293\n",
            "[4,   200] loss: 0.274\n",
            "[4,   210] loss: 0.293\n",
            "[4,   220] loss: 0.299\n",
            "[4,   230] loss: 0.336\n",
            "[4,   240] loss: 0.335\n",
            "[4,   250] loss: 0.311\n",
            "[4,   260] loss: 0.268\n",
            "[4,   270] loss: 0.285\n",
            "[4,   280] loss: 0.369\n",
            "[4,   290] loss: 0.292\n",
            "[4,   300] loss: 0.322\n",
            "[4,   310] loss: 0.311\n",
            "[4,   320] loss: 0.324\n",
            "[4,   330] loss: 0.281\n",
            "[4,   340] loss: 0.301\n",
            "[4] validation loss: 0.818\n",
            "[5,    10] loss: 0.264\n",
            "[5,    20] loss: 0.270\n",
            "[5,    30] loss: 0.318\n",
            "[5,    40] loss: 0.270\n",
            "[5,    50] loss: 0.372\n",
            "[5,    60] loss: 0.297\n",
            "[5,    70] loss: 0.240\n",
            "[5,    80] loss: 0.284\n",
            "[5,    90] loss: 0.287\n",
            "[5,   100] loss: 0.309\n",
            "[5,   110] loss: 0.236\n",
            "[5,   120] loss: 0.289\n",
            "[5,   130] loss: 0.297\n",
            "[5,   140] loss: 0.251\n",
            "[5,   150] loss: 0.289\n",
            "[5,   160] loss: 0.251\n",
            "[5,   170] loss: 0.269\n",
            "[5,   180] loss: 0.225\n",
            "[5,   190] loss: 0.276\n",
            "[5,   200] loss: 0.266\n",
            "[5,   210] loss: 0.245\n",
            "[5,   220] loss: 0.292\n",
            "[5,   230] loss: 0.278\n",
            "[5,   240] loss: 0.274\n",
            "[5,   250] loss: 0.246\n",
            "[5,   260] loss: 0.302\n",
            "[5,   270] loss: 0.238\n",
            "[5,   280] loss: 0.257\n",
            "[5,   290] loss: 0.245\n",
            "[5,   300] loss: 0.270\n",
            "[5,   310] loss: 0.224\n",
            "[5,   320] loss: 0.258\n",
            "[5,   330] loss: 0.230\n",
            "[5,   340] loss: 0.245\n",
            "[5] validation loss: 0.867\n",
            "[6,    10] loss: 0.231\n",
            "[6,    20] loss: 0.225\n",
            "[6,    30] loss: 0.254\n",
            "[6,    40] loss: 0.222\n",
            "[6,    50] loss: 0.254\n",
            "[6,    60] loss: 0.249\n",
            "[6,    70] loss: 0.255\n",
            "[6,    80] loss: 0.219\n",
            "[6,    90] loss: 0.202\n",
            "[6,   100] loss: 0.248\n",
            "[6,   110] loss: 0.225\n",
            "[6,   120] loss: 0.238\n",
            "[6,   130] loss: 0.217\n",
            "[6,   140] loss: 0.230\n",
            "[6,   150] loss: 0.258\n",
            "[6,   160] loss: 0.253\n",
            "[6,   170] loss: 0.243\n",
            "[6,   180] loss: 0.248\n",
            "[6,   190] loss: 0.182\n",
            "[6,   200] loss: 0.208\n",
            "[6,   210] loss: 0.256\n",
            "[6,   220] loss: 0.232\n",
            "[6,   230] loss: 0.227\n",
            "[6,   240] loss: 0.240\n",
            "[6,   250] loss: 0.230\n",
            "[6,   260] loss: 0.260\n",
            "[6,   270] loss: 0.206\n",
            "[6,   280] loss: 0.201\n",
            "[6,   290] loss: 0.288\n",
            "[6,   300] loss: 0.226\n",
            "[6,   310] loss: 0.223\n",
            "[6,   320] loss: 0.212\n",
            "[6,   330] loss: 0.242\n",
            "[6,   340] loss: 0.265\n",
            "[6] validation loss: 0.829\n",
            "[7,    10] loss: 0.193\n",
            "[7,    20] loss: 0.193\n",
            "[7,    30] loss: 0.196\n",
            "[7,    40] loss: 0.209\n",
            "[7,    50] loss: 0.280\n",
            "[7,    60] loss: 0.189\n",
            "[7,    70] loss: 0.230\n",
            "[7,    80] loss: 0.200\n",
            "[7,    90] loss: 0.198\n",
            "[7,   100] loss: 0.239\n",
            "[7,   110] loss: 0.251\n",
            "[7,   120] loss: 0.237\n",
            "[7,   130] loss: 0.180\n",
            "[7,   140] loss: 0.216\n",
            "[7,   150] loss: 0.194\n",
            "[7,   160] loss: 0.200\n",
            "[7,   170] loss: 0.166\n",
            "[7,   180] loss: 0.196\n",
            "[7,   190] loss: 0.250\n",
            "[7,   200] loss: 0.225\n",
            "[7,   210] loss: 0.220\n",
            "[7,   220] loss: 0.212\n",
            "[7,   230] loss: 0.210\n",
            "[7,   240] loss: 0.220\n",
            "[7,   250] loss: 0.184\n",
            "[7,   260] loss: 0.202\n",
            "[7,   270] loss: 0.179\n",
            "[7,   280] loss: 0.186\n",
            "[7,   290] loss: 0.179\n",
            "[7,   300] loss: 0.182\n",
            "[7,   310] loss: 0.179\n",
            "[7,   320] loss: 0.197\n",
            "[7,   330] loss: 0.211\n",
            "[7,   340] loss: 0.224\n",
            "[7] validation loss: 0.877\n",
            "[8,    10] loss: 0.214\n",
            "[8,    20] loss: 0.206\n",
            "[8,    30] loss: 0.176\n",
            "[8,    40] loss: 0.162\n",
            "[8,    50] loss: 0.196\n",
            "[8,    60] loss: 0.182\n",
            "[8,    70] loss: 0.176\n",
            "[8,    80] loss: 0.173\n",
            "[8,    90] loss: 0.186\n",
            "[8,   100] loss: 0.224\n",
            "[8,   110] loss: 0.162\n",
            "[8,   120] loss: 0.206\n",
            "[8,   130] loss: 0.220\n",
            "[8,   140] loss: 0.194\n",
            "[8,   150] loss: 0.163\n",
            "[8,   160] loss: 0.155\n",
            "[8,   170] loss: 0.173\n",
            "[8,   180] loss: 0.151\n",
            "[8,   190] loss: 0.209\n",
            "[8,   200] loss: 0.221\n",
            "[8,   210] loss: 0.175\n",
            "[8,   220] loss: 0.184\n",
            "[8,   230] loss: 0.185\n",
            "[8,   240] loss: 0.222\n",
            "[8,   250] loss: 0.174\n",
            "[8,   260] loss: 0.181\n",
            "[8,   270] loss: 0.158\n",
            "[8,   280] loss: 0.188\n",
            "[8,   290] loss: 0.178\n",
            "[8,   300] loss: 0.154\n",
            "[8,   310] loss: 0.156\n",
            "[8,   320] loss: 0.193\n",
            "[8,   330] loss: 0.173\n",
            "[8,   340] loss: 0.209\n",
            "[8] validation loss: 0.808\n",
            "[9,    10] loss: 0.150\n",
            "[9,    20] loss: 0.174\n",
            "[9,    30] loss: 0.234\n",
            "[9,    40] loss: 0.158\n",
            "[9,    50] loss: 0.192\n",
            "[9,    60] loss: 0.169\n",
            "[9,    70] loss: 0.134\n",
            "[9,    80] loss: 0.179\n",
            "[9,    90] loss: 0.146\n",
            "[9,   100] loss: 0.155\n",
            "[9,   110] loss: 0.205\n",
            "[9,   120] loss: 0.165\n",
            "[9,   130] loss: 0.165\n",
            "[9,   140] loss: 0.148\n",
            "[9,   150] loss: 0.184\n",
            "[9,   160] loss: 0.149\n",
            "[9,   170] loss: 0.171\n",
            "[9,   180] loss: 0.175\n",
            "[9,   190] loss: 0.162\n",
            "[9,   200] loss: 0.203\n",
            "[9,   210] loss: 0.147\n",
            "[9,   220] loss: 0.155\n",
            "[9,   230] loss: 0.177\n",
            "[9,   240] loss: 0.201\n",
            "[9,   250] loss: 0.144\n",
            "[9,   260] loss: 0.140\n",
            "[9,   270] loss: 0.188\n",
            "[9,   280] loss: 0.156\n",
            "[9,   290] loss: 0.163\n",
            "[9,   300] loss: 0.145\n",
            "[9,   310] loss: 0.147\n",
            "[9,   320] loss: 0.156\n",
            "[9,   330] loss: 0.160\n",
            "[9,   340] loss: 0.146\n",
            "[9] validation loss: 0.880\n",
            "[10,    10] loss: 0.147\n",
            "[10,    20] loss: 0.154\n",
            "[10,    30] loss: 0.154\n",
            "[10,    40] loss: 0.166\n",
            "[10,    50] loss: 0.176\n",
            "[10,    60] loss: 0.122\n",
            "[10,    70] loss: 0.149\n",
            "[10,    80] loss: 0.178\n",
            "[10,    90] loss: 0.161\n",
            "[10,   100] loss: 0.154\n",
            "[10,   110] loss: 0.166\n",
            "[10,   120] loss: 0.179\n",
            "[10,   130] loss: 0.158\n",
            "[10,   140] loss: 0.136\n",
            "[10,   150] loss: 0.143\n",
            "[10,   160] loss: 0.208\n",
            "[10,   170] loss: 0.148\n",
            "[10,   180] loss: 0.168\n",
            "[10,   190] loss: 0.149\n",
            "[10,   200] loss: 0.132\n",
            "[10,   210] loss: 0.153\n",
            "[10,   220] loss: 0.190\n",
            "[10,   230] loss: 0.141\n",
            "[10,   240] loss: 0.153\n",
            "[10,   250] loss: 0.125\n",
            "[10,   260] loss: 0.148\n",
            "[10,   270] loss: 0.142\n",
            "[10,   280] loss: 0.126\n",
            "[10,   290] loss: 0.156\n",
            "[10,   300] loss: 0.158\n",
            "[10,   310] loss: 0.125\n",
            "[10,   320] loss: 0.151\n",
            "[10,   330] loss: 0.150\n",
            "[10,   340] loss: 0.138\n",
            "[10] validation loss: 0.848\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hr8xGwCi4Gy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "class SampleDataset(Dataset):\n",
        "    def __init__(self, sample_dir, transform=None):\n",
        "        self.sample_dir = sample_dir\n",
        "        self.transform = transform\n",
        "        self.filenames = os.listdir(sample_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with rasterio.open(os.path.join(self.sample_dir, self.filenames[idx])) as src:\n",
        "            sample_image = src.read().transpose((1, 2, 0))\n",
        "        if self.transform:\n",
        "            sample_image = self.transform(sample_image)\n",
        "        return sample_image\n",
        "\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "sample_dataset = SampleDataset('/content/sample_data/inference_data', transform=transform)\n",
        "\n",
        "# DataLoader\n",
        "sample_loader = DataLoader(sample_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Inference loop\n",
        "results = []\n",
        "for data in sample_loader:\n",
        "    inputs = data.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)['out']\n",
        "    _, predicted_labels = torch.max(outputs, dim=1)\n",
        "    predicted_labels = predicted_labels.squeeze().cpu().numpy()\n",
        "    results.append(predicted_labels)\n",
        "\n",
        "# Save results as new GeoTIFF files\n",
        "for i, filename in enumerate(sample_dataset.filenames):\n",
        "    input_filepath = os.path.join('/content/sample_data/inference_data', filename)\n",
        "    output_filepath = os.path.join('/content/drive/MyDrive/Colab_Demo/Murrieta_Result_4/Predictions', filename)\n",
        "\n",
        "    with rasterio.open(input_filepath) as src:\n",
        "        meta = src.meta\n",
        "\n",
        "    num_classes = outputs.shape[1]\n",
        "    meta.update(count=num_classes, dtype=np.uint8)\n",
        "\n",
        "    with rasterio.open(output_filepath, 'w', **meta) as dst:\n",
        "        for band in range(num_classes):\n",
        "            dst.write(results[i] == band, band + 1)\n"
      ],
      "metadata": {
        "id": "SJlz2Jriz_tY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = torch.nn.Softmax(dim=1)\n",
        "for i, data in enumerate(sample_loader):\n",
        "    inputs = data[0].to(device)  # Access the sample image from the batch\n",
        "    filename = sample_dataset.filenames[i]\n",
        "    output_filepath = os.path.join('/content/drive/MyDrive/Colab_Demo/Murrieta_Result_4/Predictions', filename)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)['out']\n",
        "        _, predicted_labels = torch.max(outputs, dim=1)\n",
        "        probabilities = softmax(outputs) \n",
        "        predicted_labels = predicted_labels.squeeze().cpu().numpy()\n",
        "\n",
        "    with rasterio.open(os.path.join('/content/sample_data/inference_data', filename)) as src:\n",
        "        meta = src.meta\n",
        "\n",
        "    num_classes = outputs.shape[1]\n",
        "    meta.update(count=num_classes, dtype=np.uint8)\n",
        "\n",
        "    with rasterio.open(output_filepath, 'w', **meta) as dst:\n",
        "        for band in range(num_classes):\n",
        "            dst.write((predicted_labels == band).astype(np.uint8), band + 1)\n"
      ],
      "metadata": {
        "id": "IdXDo9T_2DhC",
        "outputId": "29483c77-619c-4b88-f721-99de5b8e515d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-efccbc57525c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inference loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-574940621dce>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aaXzBHI3lHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results[0] \n",
        "\n",
        "_, predicted_labels = torch.max(results[0], dim=0)\n",
        "\n",
        "predicted_labels.numpy()"
      ],
      "metadata": {
        "id": "FXFvuyUz2050",
        "outputId": "56db3ac0-6dc4-49ad-a01e-fc409372c722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ff86ea655048>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    }
  ]
}