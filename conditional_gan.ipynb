{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seismosmsr/machine_learning/blob/main/conditional_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y50GdAhdqtgY"
      },
      "source": [
        "# Conditional GAN\n",
        "**Author:** [Aron Boettcher](spectral.online)<br>\n",
        "**Adapted from:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/07/13<br>\n",
        "**Last modified:** 2021/07/15<br>\n",
        "**Description:** Training a GAN conditioned on class labels to generate handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-meO-8ffqtgZ"
      },
      "source": [
        "Generative Adversarial Networks (GANs) let us generate novel image data, video data,\n",
        "or audio data from a random input. Typically, the random input is sampled\n",
        "from a normal distribution, before going through a series of transformations that turn\n",
        "it into something plausible (image, video, audio, etc.).\n",
        "\n",
        "However, a simple [DCGAN](https://arxiv.org/abs/1511.06434) doesn't let us control\n",
        "the appearance (e.g. class) of the samples we're generating. For instance,\n",
        "with a GAN that generates MNIST handwritten digits, a simple DCGAN wouldn't let us\n",
        "choose the class of digits we're generating.\n",
        "To be able to control what we generate, we need to _condition_ the GAN output\n",
        "on a semantic input, such as the class of an image.\n",
        "\n",
        "In this example, we'll build a **Conditional GAN** that can generate MNIST handwritten\n",
        "digits conditioned on a given class. Such a model can have various useful applications:\n",
        "\n",
        "* let's say you are dealing with an\n",
        "[imbalanced image dataset](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data),\n",
        "and you'd like to gather more examples for the skewed class to balance the dataset.\n",
        "Data collection can be a costly process on its own. You could instead train a Conditional GAN and use\n",
        "it to generate novel images for the class that needs balancing.\n",
        "* Since the generator learns to associate the generated samples with the class labels,\n",
        "its representations can also be used for [other downstream tasks](https://arxiv.org/abs/1809.11096).\n",
        "\n",
        "Following are the references used for developing this example:\n",
        "\n",
        "* [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784)\n",
        "* [Lecture on Conditional Generation from Coursera](https://www.coursera.org/lecture/build-basic-generative-adversarial-networks-gans/conditional-generation-inputs-2OPrG)\n",
        "\n",
        "If you need a refresher on GANs, you can refer to the \"Generative adversarial networks\"\n",
        "section of\n",
        "[this resource](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-12/r-3/232).\n",
        "\n",
        "This example requires TensorFlow 2.5 or higher, as well as TensorFlow Docs, which can be\n",
        "installed using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V8Zi-apyqtgZ",
        "outputId": "e4922c40-da95-46a2-caa0-a8e6a9cdb02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE4an01rqtga"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M4msdB2Qqtga"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow_docs.vis import embed\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lTXrmg8qtga"
      },
      "source": [
        "## Constants and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7RCu_-uVqtga"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "num_channels = 1\n",
        "num_classes = 101\n",
        "image_size = 512\n",
        "latent_dim = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw35q14Sqtgb"
      },
      "source": [
        "## Loading the MNIST dataset and preprocessing it"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# I switched to pngs and jpgs to try and use tensorflows native vectorization\n",
        "#todo: get gdal working so you can just use geotiff\n",
        "url = 'https://drive.google.com/uc?id=1kwU_CkP1X5M1CDlYKPkb9p5J8GulWBXr'\n",
        "output = 'sample_test.csv'\n",
        "\n",
        "#Update with proper validation data\n",
        "# https://drive.google.com/file/d/1unLB1XCJHoul3gqGYGzqSS8QMr5ZvJ9h/view?usp=sharing\n",
        "gdown.download(url,output,quiet = False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1graojPHaMvZGHmocsUFLds9bFWQG_mr6'\n",
        "output = 'sample_train.csv'\n",
        "\n",
        "#Update with proper validation data\n",
        "# https://drive.google.com/file/d/1unLB1XCJHoul3gqGYGzqSS8QMr5ZvJ9h/view?usp=sharing\n",
        "gdown.download(url,output,quiet = False)\n",
        "# cwd = os.getcwd()\n",
        "# with zipfile.ZipFile(cwd+'/sample.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall(cwd+'/sample')\n",
        "\n",
        "# PATH = os.path.join(os.path.dirname(cwd+'/sample/'), 'sample/')\n",
        "# print(PATH)"
      ],
      "metadata": {
        "id": "9724Jbw9sRSb",
        "outputId": "4c508c64-3e92-4d65-d4fe-dabc093e47a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kwU_CkP1X5M1CDlYKPkb9p5J8GulWBXr\n",
            "To: /content/sample_test.csv\n",
            "100%|██████████| 137M/137M [00:00<00:00, 146MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1graojPHaMvZGHmocsUFLds9bFWQG_mr6\n",
            "To: /content/sample_train.csv\n",
            "100%|██████████| 13.8G/13.8G [01:36<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sample_train.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate n real samples with class labels\n",
        "def generate_real_samples(s,filename = '/content/sample.csv'):\n",
        "  import random\n",
        "  import pandas\n",
        "  import numpy\n",
        "\t# Sample s rows of data.frame\n",
        "\n",
        "  #number of records in file (excludes header)\n",
        "  n = sum(1 for line in open(filename)) - 1 \n",
        "\n",
        "  #the 0-indexed header will not be included in the skip list\n",
        "  skip = sorted(random.sample(range(1,n+1),n-s)) \n",
        "  df = pandas.read_csv(filename, skiprows=skip)\n",
        "  X = []\n",
        "  for i in range(len(df.index)):\n",
        "    text_exa = df['rh'][i]\n",
        "    text_exa = str(text_exa).replace(\"{\",\"\").replace(\"}\", \"\")\n",
        "    test_exa = text_exa.split(\",\")\n",
        "    test_exa = [float(i) for i in test_exa]\n",
        "    # test_exa = test_exa\n",
        "    X.append(test_exa)\n",
        "\n",
        "\n",
        "\t# generate class labels\n",
        "  y = []\n",
        "  for i in range(len(df.index)):\n",
        "    # y_one = numpy.ones(1)\n",
        "    y_one = df['ls'][i]\n",
        "    y_one = str(y_one).replace(\"{\",\"\").replace(\"}\", \"\")\n",
        "    y_one = y_one.split(\",\")\n",
        "    y_one = [float(i) for i in y_one]\n",
        "    y.append(y_one)\n",
        "\n",
        "    \n",
        "  X = numpy.array(X)\n",
        "  y = numpy.array(y)\n",
        "\n",
        "  # X = (X.astype(\"float32\") / 65455.0).astype(\"float32\")\n",
        "  # y =(y.astype(\"float32\")+100)/255\n",
        "  X = ((X.astype(\"float32\")+100/255)).astype(\"float32\")\n",
        "  y =(y.astype(\"float32\")/ 65455.0).astype(\"float32\")\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "Bu4Q-00Hu63I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_real_samples(2)"
      ],
      "metadata": {
        "id": "iUZVkDJYvAyU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u99NsBjlqtgb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# We'll use all the available examples from both the training and test\n",
        "# sets.\n",
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "(x_train, y_train) = generate_real_samples(450000,filename = '/content/sample_train.csv')\n",
        "(x_test, y_test) = generate_real_samples(2000,filename = '/content/sample_test.csv')\n",
        "\n",
        "# all_pixels = x_train\n",
        "# all_labels = np.concatenate([y_train, y_test])\n",
        "\n",
        "# # Scale based on reflectence values:\n",
        "# # https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_L2?hl=en#bands\n",
        "# x_train = (x_train.astype(\"float32\") / 65455.0).astype(\"float32\")\n",
        "# all_labels =(y_train.astype(\"float32\")+100)/255\n",
        "\n",
        "# x_test = (x_test.astype(\"float32\") / 65455.0).astype(\"float32\")\n",
        "# y_test =(y_test.astype(\"float32\")+100)/255\n",
        "# # Create tf.data.Dataset.\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((y_train,x_train))\n",
        "dataset_train = dataset_train.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((y_test,x_test))\n",
        "dataset_test = dataset_test.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# print(f\"Shape of training images: {all_labels[1]}\")\n",
        "# print(f\"Shape of training images: {all_pixels.shape}\")\n",
        "# print(f\"Shape of training labels: {all_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x_train[1])"
      ],
      "metadata": {
        "id": "g701wfbmj94D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35LbRuf5qtgb"
      },
      "source": [
        "## Calculating the number of input channel for the generator and discriminator\n",
        "\n",
        "In a regular (unconditional) GAN, we start by sampling noise (of some fixed\n",
        "dimension) from a normal distribution. In our case, we also need to account\n",
        "for the class labels. We will have to add the number of classes to\n",
        "the input channels of the generator (noise input) as well as the discriminator\n",
        "(generated image input)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAlWShbvqtgc",
        "outputId": "7cd2c276-2c47-4aa0-daa6-29837b5a5e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024 613\n"
          ]
        }
      ],
      "source": [
        "generator_in_channels = latent_dim + image_size\n",
        "discriminator_in_channels = image_size + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmsGUffgqtgc"
      },
      "source": [
        "## Creating the discriminator and generator\n",
        "\n",
        "The model definitions (`discriminator`, `generator`, and `ConditionalGAN`) have been\n",
        "adapted from [this example](https://keras.io/guides/customizing_what_happens_in_fit/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2niCQ0yXqtgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52c3d68-5606-437a-c262-d0e4b1e0e404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.ops.gen_math_ops import sigmoid\n",
        "from keras import Input\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Concatenate\n",
        "from keras import Model\n",
        "\n",
        "# Create the discriminator.\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((discriminator_in_channels,)),\n",
        "     \n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "     \n",
        "        layers.Dense(1,activation = 'sigmoid'),\n",
        "    ],\n",
        "    name=\"discriminator\",)\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((generator_in_channels,)),\n",
        "     \n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Reshape(target_shape=(2,512)),\n",
        "        layers.Dropout(.25),\n",
        "        layers.LSTM(32, activation=\"relu\",return_sequences=True),\n",
        "     \n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "\n",
        "        layers.Dense(num_classes,  activation=\"linear\"),\n",
        "    ],\n",
        "    name=\"generator\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYXoy-O_qtgc"
      },
      "source": [
        "## Creating a `ConditionalGAN` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uT_y3xRwqtgd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConditionalGAN(keras.Model):\n",
        "  \n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(ConditionalGAN, self).__init__()\n",
        "        # Create the discriminator.\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(ConditionalGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_pixels, real_labels = data\n",
        "        # print(real_pixels[0])\n",
        "        # Sample random points in the latent space and concatenate the labels.\n",
        "        # This is for the generator.\n",
        "        batch_size = tf.shape(real_pixels)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        # print(random_latent_vectors[0])\n",
        "        random_vector_pixels = tf.concat(\n",
        "            [random_latent_vectors, real_pixels], axis=1\n",
        "        )\n",
        "        # print(random_vector_pixels[0])\n",
        "        # Decode the noise (guided by labels) to fake images.\n",
        "        generated_labels = self.generator(random_vector_pixels)\n",
        "\n",
        "        # Combine them with real images. Note that we are concatenating the labels\n",
        "        # with these images here.\n",
        "        fake_pixel_and_labels = tf.concat([generated_labels, real_pixels], -1)\n",
        "        real_pixel_and_labels = tf.concat([real_labels, real_pixels], -1)\n",
        "        combined_images = tf.concat(\n",
        "            [fake_pixel_and_labels, real_pixel_and_labels], axis=0\n",
        "        )\n",
        "\n",
        "        # Assemble labels discriminating real from fake images.\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space.\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, real_pixels], axis=1\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_labels = self.generator(random_vector_labels)\n",
        "            fake_pixels_and_labels = tf.concat([real_pixels, fake_labels], -1)\n",
        "            predictions = self.discriminator(fake_pixels_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L8GawiTqtge"
      },
      "source": [
        "## Training the Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cond_gan = ConditionalGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
        ")\n",
        "cond_gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")"
      ],
      "metadata": {
        "id": "kv6SGSH9G83I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I29l7pJCqtge",
        "outputId": "721352eb-c126-42e7-eac7-8e31d8b8235b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "977/977 [==============================] - 56s 44ms/step - g_loss: 0.4644 - d_loss: 0.0698\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  (x_train, y_train) = generate_real_samples(250000,filename = '/content/sample_train.csv')\n",
        "  (x_test, y_test) = generate_real_samples(20000,filename = '/content/sample_test.csv')\n",
        "  dataset_train = tf.data.Dataset.from_tensor_slices((y_train,x_train))\n",
        "  dataset_train = dataset_train.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "  dataset_test = tf.data.Dataset.from_tensor_slices((y_test,x_test))\n",
        "  dataset_test = dataset_test.shuffle(buffer_size=1024).batch(batch_size)\n",
        "  \n",
        "  \n",
        "  cond_gan.fit(dataset_train, epochs=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rfRnGG2qtge"
      },
      "source": [
        "## Interpolating between classes with the trained generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Input\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Concatenate\n",
        "from keras import Model\n",
        "\n",
        "input_layer = Input(shape=(512))\n",
        "\n",
        "dense1 = Dense(1024, activation='relu')(input_layer)\n",
        "resh1 = Reshape(target_shape=(2,512))(dense1)\n",
        "dropout1 =  Dropout(.25)(resh1)\n",
        "lstm1 = LSTM(32, activation=\"relu\",return_sequences=True)(dropout1)\n",
        "# flat1 = Flatten()(lstm1)\n",
        "# flat2 = Flatten()(resh1)\n",
        "# conc1 = Concatenate(axis=1)([flat1,flat2])\n",
        "\n",
        "dense2 = Dense(512, activation='relu')(lstm1)\n",
        "resh2 = Reshape(target_shape=(2,512))(dense2)\n",
        "dropout2 =  Dropout(.25)(resh2)\n",
        "lstm2 = LSTM(32, activation=\"relu\",return_sequences=True)(dropout2)\n",
        "# flat3 = Flatten()(lstm2)\n",
        "# flat4 = Flatten()(resh2)\n",
        "# conc2 = Concatenate(axis=1)([flat3,flat4])\n",
        "\n",
        "dense3 = Dense(512, activation='relu')(lstm2)\n",
        "resh3 = Reshape(target_shape=(2,512))(dense3)\n",
        "dropout3 =  Dropout(.25)(resh3)\n",
        "lstm3 = LSTM(32, activation=\"relu\",return_sequences=True)(dropout3)\n",
        "# flat5 = Flatten()(lstm3)\n",
        "# flat6 = Flatten()(resh3)\n",
        "# conc3 = Concatenate(axis=1)([flat5,flat6])\n",
        "dense4 = Dense(512, activation='relu')(lstm3)\n",
        "flat6 = Flatten()(dense4)\n",
        "\n",
        "dense4 = Dense(1024, activation='relu')(flat6)\n",
        "\n",
        "output_layer = Dense(101, activation='linear')(dense4)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "optz = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss=\"MeanSquaredError\", optimizer=optz,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "57KkLbzGmeih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Input\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from keras import Model\n",
        "input_layer = Input(shape=(512))\n",
        "dense1 = Dense(1024, activation='relu')(input_layer)\n",
        "dense2 = Dense(1024, activation='relu')(dense1)\n",
        "dropout1 =  Dropout(.25)(dense2)\n",
        "resh1 = Reshape(target_shape=(1,16,64))(dropout1)\n",
        "conv1 = Conv1D(filters=32,\n",
        "               kernel_size=16,\n",
        "               strides=1,\n",
        "               activation='relu')(resh1)\n",
        "resh1 = Reshape(target_shape=(32,1))(conv1)\n",
        "pool1 = MaxPooling1D(pool_size=2)(resh1)\n",
        "lstm1 = LSTM(32, activation=\"relu\")(pool1)\n",
        "output_layer = Dense(101, activation='linear')(lstm1)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss=\"MeanSquaredError\", optimizer=optimizer,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "buysgMLnaQzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "_lz0cJKtuYye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  (x_train, y_train) = generate_real_samples(500000,filename = '/content/sample_train.csv')\n",
        "  (x_test, y_test) = generate_real_samples(20000,filename = '/content/sample_test.csv')\n",
        "\n",
        "\n",
        "  dataset_train = tf.data.Dataset.from_tensor_slices((y_train,x_train))\n",
        "  dataset_train = dataset_train.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "  dataset_test = tf.data.Dataset.from_tensor_slices((y_test,x_test))\n",
        "  dataset_test = dataset_test.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "  model.fit(dataset_train,validation_data =dataset_test , epochs=10)"
      ],
      "metadata": {
        "id": "daL_IqxrawiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import numpy as np\n",
        "# # import tensorflow as tf\n",
        "\n",
        "# (x_train, y_train) = generate_real_samples(300000,filename = '/content/sample_train.csv')\n",
        "# (x_test, y_test) = generate_real_samples(2000,filename = '/content/sample_test.csv')\n",
        "\n",
        "\n",
        "# dataset_train = tf.data.Dataset.from_tensor_slices((y_train,x_train))\n",
        "# dataset_train = dataset_train.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# dataset_test = tf.data.Dataset.from_tensor_slices((y_test,x_test))\n",
        "# dataset_test = dataset_test.shuffle(buffer_size=1024).batch(batch_size)\n"
      ],
      "metadata": {
        "id": "nqXfED27qHJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(real_labels, real_pixels) = generate_real_samples(batch_size,filename = '/content/sample_test.csv')\n",
        "p_test = model.predict(real_pixels)\n",
        "\n",
        "\n",
        "err_vec = (p_test-real_labels)\n",
        "\n",
        "mean_err_vec = (np.mean(err_vec,axis=0))\n",
        "mean_label_vec = (np.mean(real_labels,axis=0))\n",
        "mean_pred_vec = (np.mean(p_test,axis=0))\n",
        "fig, ax = plt.subplots()\n",
        "m = 21\n",
        "for i in range(batch_size):\n",
        "  ax.plot(p_test[i],real_labels[i],label=i)\n",
        "\n",
        "# ax.plot(mean_label_vec,mean_err_vec,color='black')\n",
        "ax.plot(mean_pred_vec,mean_label_vec,color='black')\n",
        "# plt.plot([-0.02, 0.07], [-0.02, 0.07], 'k-', lw=2)\n",
        "ax.set(xlabel='predicted waveform', ylabel='truth waveform',\n",
        "       title='About as simple as it gets, folks')\n",
        "ax.grid()\n",
        "\n",
        "# fig.savefig(\"test.png\")\n",
        "plt.show()\n",
        "# print(np.mean(np.mean(p_test,axis=1)))"
      ],
      "metadata": {
        "id": "-7MICnxHhgk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "m = 21\n",
        "for i in range(64):\n",
        "  ax.plot(p_test[i]*255, real_labels[i]*255,label=i)\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='voltage (mV)',\n",
        "       title='About as simple as it gets, folks')\n",
        "ax.grid()\n",
        "\n",
        "# fig.savefig(\"test.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TQvcREk2mbBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cua32XZzqtgf"
      },
      "outputs": [],
      "source": [
        "# We first extract the trained generator from our Conditiona GAN.\n",
        "trained_gen = cond_gan.generator\n",
        "(real_labels, real_pixels) = generate_real_samples(batch_size,filename = '/content/sample_test.csv')\n",
        "\n",
        "# batch_size = tf.shape(real_pixels)[0]\n",
        "random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "# print(random_latent_vectors[0])\n",
        "random_vector_pixels = tf.concat(\n",
        "    [random_latent_vectors, real_pixels], axis=1\n",
        ")\n",
        "# print(real_labels[1])\n",
        "\n",
        "generated_waveform = trained_gen(random_vector_pixels)\n",
        "\n",
        "# print(generated_waveform[1])\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(generated_waveform[1], real_labels[1])\n",
        "\n",
        "ax.set(xlabel='time (s)', ylabel='voltage (mV)',\n",
        "       title='About as simple as it gets, folks')\n",
        "ax.grid()\n",
        "\n",
        "# fig.savefig(\"test.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mZ3cRFIqtgf"
      },
      "source": [
        "Here, we first sample noise from a normal distribution and then we repeat that for\n",
        "`num_interpolation` times and reshape the result accordingly.\n",
        "We then distribute it uniformly for `num_interpolation`\n",
        "with the label indentities being present in some proportion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecm5BFWJqtgg"
      },
      "outputs": [],
      "source": [
        "fake_images *= 255.0\n",
        "converted_images = fake_images.astype(np.uint8)\n",
        "converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
        "imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n",
        "embed.embed_file(\"animation.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rokmd_Wtqtgg"
      },
      "source": [
        "We can further improve the performance of this model with recipes like\n",
        "[WGAN-GP](https://keras.io/examples/generative/wgan_gp).\n",
        "Conditional generation is also widely used in many modern image generation architectures like\n",
        "[VQ-GANs](https://arxiv.org/abs/2012.09841), [DALL-E](https://openai.com/blog/dall-e/),\n",
        "etc.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/conditional-gan) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/conditional-GAN)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "conditional_gan",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}